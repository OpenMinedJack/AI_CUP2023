{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "281f6c8b-735a-4716-9afa-7798651be6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "p = sns.color_palette()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b04b2254-3fc3-44de-80a0-c2ca8dc5fa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd02c1ad-30d2-4521-9023-3b30dee3c304",
   "metadata": {},
   "outputs": [],
   "source": [
    "#自訂函式庫\n",
    "from PredateFiletext import GetfileTxtContent as GT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6f750c-e103-4417-bcb7-81b0d8b8969f",
   "metadata": {},
   "source": [
    "## 0. File Path & Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb9d400f-a551-4da1-a6f1-83b0cab95b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#儲存文件路徑\n",
    "file_path_array=[]\n",
    "file_name_array=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d550f17f-6278-4708-932b-6034dfb932c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "473"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 遍歷並排序所有匹配的*.txt文件，按文件名由小到大排序\n",
    "# txt_files = glob.glob('Train_Text_Dataset/*.txt', recursive=True)\n",
    "# txt_files = glob.glob('Validation_Release/*.txt', recursive=True)\n",
    "txt_files = glob.glob('opendid_test/*.txt', recursive=True)\n",
    "sorted_txt_files = sorted(txt_files, key=lambda x: os.path.basename(x))\n",
    "for file_path in sorted_txt_files:\n",
    "    file_name = os.path.basename(file_path)  # 提取文件名部分\n",
    "    if file_name.startswith(\"file\"):\n",
    "        # 移除文件擴展名 .txt\n",
    "        file_name_without_extension = os.path.splitext(file_name)[0]\n",
    "        file_name_array.append(file_name_without_extension)\n",
    "len(file_name_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecf7e411-c0ec-484e-927c-2507b5fcbd05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "473"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 遍歷並排序所有匹配的*file.txt文件，按文件名由小到大排序 \n",
    "# txt_files = glob.glob('./Train_Text_Dataset/*.txt', recursive=True)\n",
    "# txt_files = glob.glob('./Validation_Release/*.txt', recursive=True)\n",
    "txt_files = glob.glob('opendid_test/*.txt', recursive=True)\n",
    "sorted_txt_files = sorted(txt_files, key=lambda x: os.path.basename(x))\n",
    "# 僅讀取檔名以 \"file\" 開頭的文件\n",
    "for file_path in sorted_txt_files:\n",
    "    file_name = os.path.basename(file_path)\n",
    "    if file_name.startswith(\"file\"):\n",
    "        file_path_array.append(file_path)\n",
    "len(file_path_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c8ee6c-f0fe-4bfa-bfa7-960374464193",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1. 測試驗證函式庫(自訂)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b249842d-13e9-4c37-9e0f-3c4a63a0fe48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"SPR no: 73C471159N\\nMRN no: 73147115\\nSite_name: SHELLHARBOUR HOSPITAL\\nFacility_id: 016\\nSpecimen_type: Fresh Tissue\\nPathology Report73C47115 (73C471159N) Isaiah, Manduway'Douglass\\n\\nHISTOPATHOLOGY REPORT:\\n\\nHISTORY:\\nPeritoneal nodule.  Previous colorectal CA.  For frozen section.  Lymph node for frozen section.  Rectal CA.  Pelvic exenteration.  Rectum, bladder, peritoneal tumour.\\n\\nMACROSCOPIC:\\nA  &amp;quot;PERITONEAL NODULE&amp;quot;.  A piece of tissue 15x12x10mm with fat on the deep aspect and surface smooth, semi-transparent fluctuant 12mm nodule.  Cut surface cyst containing thick clear mucoid material.  Two transverse sections for frozen section.\\n\\nF/S:  &amp;quot;Benign cystic process, probable cystic fat necrosis&amp;quot;.  Result to anaesthetist at 10:40hrs on 29/05/2066 by Dr U. Moulinos.\\n\\n(1  frozen section; 2  remainder).  AE (M-2).\\n\\nB  &amp;quot;LYMPH NODE 1&amp;quot;.  A piece of fat 45x35x15mm containing a fatty lymph node 20x15x10mm.  A second smaller lymph node 6x5x5mm.\\n\\nF/S:&amp;quot;One large vessel and one negative node&amp;quot;\\n\\n(1  TS of bladder node; 2  all of smaller node; 3-5  rest of larger node).  RS (M-5).\\n\\nC  &amp;quot;LYMPH NODE 2&amp;quot;.  A lymph node 6x5x5mm.  AE (1-1).\\n\\nF/S:  &amp;quot;Negative&amp;quot;.  (No evidence of malignancy).\\n\\nB &amp;amp; C Reported to Prof Sonny by EC at 12:55hrs on 29/05/2068.\\n\\nD  &amp;quot;COLON, BLADDER, PROSTATE, OMENTUM&amp;quot;.  A segment of large bowel.  Bladder and prostate received enbloc and separately a piece of fatty tissue consistent with omentum. The segment of large bowel measures 180mm in length and with a diameter of 20mm distally and 25mm proximally.  Close to the proximal end of the rectum there is disruption over an area measuring 70mm in length x 30mm in diameter over the posterior aspect.  Within this area, tumour is seen.  The rest of the outer most aspect is roughened with multiple areas of adhesion.  The prostate is 32mm from apex to base x 45mm left to right x 45mm anterior to posterior.  Seminal vesicles are not easily identifiable externally but visible on sectioning.  The bladder is 50mm from dome to base of prostate, 50mm anterior to posterior and 45mm left to right.  There is a clipped tubular structure noted on the right side.  It measures 45mm in length with a maximum diameter of 6mm, ? right ureter.  On the left side is a clipped tubular structure measuring 15mm x 6mm maximum diameter, ? left ureter.  Presumed proximal margin of segment of large bowel is inked blue, presumed distal margin black.  Disrupted area with tumour inked red.  The left side of prostate and bladder inked blue.  Right side of prostate and bladder inked green.  On sectioning there is a fungating tumour noted within the rectum with direct invasion through the wall of the rectum with dense fibrosis and an adjacent cystic cavity on the posterior wall of the bladder.  The tumour is 60mm in length x 40mm in maximum diameter and lies close to the proximal and radial margins and is 70mm from distal margin.  No serosa is seen over the irregular surface of the posterior circumferential margin of the rectal mass. However the other margins appear clear.  The mucosa of the bladder is focally congested\\n\\n(1  distal margin of presumed right ureter; 2  distal margin of presumed left ureter; 3&amp;amp;4  LS of proximal soft tissue circumferential margin of bowel; 5  distal margin of bowel; 6&amp;amp;7  distal edge of tumour including normal mucosa; 8  section through area of disruption showing tumour involvement at the disrupted surface; 9  tumour in relation to posterior wall of prostate; 10  tumour in relation to bladder wall includes roughened bladder mucosa; 11  tumour in relation to ?seminal vesicle; 12  composite slice of 11 includes bladder wall; 13  tumour bladder wall and bladder mucosa; 14&amp;amp;15  composite slice of anterior wall of prostate [14 base in relation to bladder, 15  apex]; 16-18  prostate posterior wall [16  apical marginex, 17&amp;amp;18  composite slices of base]; 19  one further section of tumour immediately adjacent to prostate; 20  two possible lymph nodes were identified and embedded).\\n\\nA separate piece of fatty tissue consistent with omentum, altogether measures 230x110x30mm.  There are some firm areas identified on sectioning through this area.  It appears to be bowel mucosa adherent to the omentum.  There is also a tumour deposit noted involving the omentum 6mm in diameter with a mucinous appearance.\\n\\n(21 adherent segment of bowel; 22-23 section of omentum [23  showing involvement of tumour]).  RS (M-23).\\n\\nAdditional blocks:  (24&amp;amp;25  tumour into the colonic mucosa; 26&amp;amp;27  section of ?abscess between bladder wall and colonic wall; 28  transverse shave of possible proximal margin; 29-32  sections through ragged CRM area inked red; 33-40  posterior prostate wall incontinuity with bladder embedded from apex to bladder [33  apex, 34-36  composite slices [34  includes bowel mucosa, 35  ?seminal vesicles, 36  base of prostate], 37&amp;amp;38  composite slices [37  includes bowel mucosa, 38  bladder wall with possible bladder mucosa], 39&amp;amp;40  composite slices [39  showing bowel mucosa, 40  bladder mucosa]]; 41-43  mesocolic fat, no definite nodes identified; 44,45 peri-rectal nodes, 46, 47 proximal CRM inked red).  RS (M-47/MC/EM/km).\\n\\nE  &amp;quot;DISTAL RIGHT URETER&amp;quot;.  A tubular piece of tissue with suture at one end.  It measures 20mm in length with a maximum diameter of 5mm.  Sutured end is inked blue.  On sectioning, there is mucinous material in the wall of the ureter.\\n\\n(1  sutured end; 2  section immediately adjacent to sutured end; 3  remainder).  AE (M-3).\\n\\nF  &amp;quot;DISTAL LEFT URETER&amp;quot;.  A piece of tubular tissue with suture at one end.  It measures 32mm in length with a maximum diameter of 4mm.  The serosa is unremarkable.  Sutured end is inked blue.\\n\\n(1  sutured end; 2  section immediately adjacent to sutured end; 3  TS in between; 4  opposite (unsutured end]).  AE (M-4).\\n\\nG  &amp;quot;PARA-AORTIC LYMPH NODE&amp;quot;.  A piece of fatty tissue 40x25x12mm.  On sectioning, one possible lymph node identified.  Transversely sectioned.  AE (M-3).\\n\\nH  &amp;quot;COMMON ILIAC LYMPH NODE&amp;quot;.  Three pieces of fatty tissue in aggregate, 30x25x6mm with three possible lymph nodes.\\n\\n(1  one lymph node; 2  one lymph node; 3  one lymph node).  AE (M-3/LK/km).\\n\\nMICROSCOPIC (Dr U Cranmer)\\nA.  Histology shows fibrofatty tissue with foci of fibrous scarring and focal fat necrosis.  There is no evidence of malignancy.  There is also a small amount of foreign refractile material consistent with previous surgery at this site.\\n\\nB.  No evidence of malignancy is seen in one lymph node.  Additionally, there is also a small artery which shows luminal occlusion with partial recanalisation by small vessels and inflamed granulation tissue representing organised thrombus.  There is no evidence of malignancy.\\n\\nC.  No evidence of malignancy is seen in one lymph node.\\n\\nD.  Histology shows a moderately differentiated mucinous adenocarcinoma arising within the rectum with infiltration through muscularis propria and into perirectal fatty tissue.  At this site, there are dense fibrous inflammatory adhesions with a chronic abscess which lies between the anterior rectum and the posterior wall of the bladder and adjacent prostate.  There is no direct tumour infiltration of the bladder wall, prostate or seminal vesicles by malignancy.  At the ragged area macroscopically seen at the posterior rectal circumferential resection margin, mucinous adenocarcinoma lies at the inked resection margin but all other margins are clear.  Focal perineural invasion is identified but no vascular lymphatic invasion is seen.  No malignancy is seen in 7 peri-rectal lymph nodes.  A 6mm deposit of metastatic mucinous adenocarcinoma is seen within omental fat.  The bladder wall shows moderate chronic cystitis with polypoidal features, with focal mucosal ulceration but no evidence of urothelial atypia.  The ureteric resection margins are unremarkable.  The prostate shows benign nodular hyperplasia.\\n\\nSynoptic summary:\\n\\nTumour type:  Mucinous adenocarcinoma\\n\\nHistologic grade:  Low-grade (moderately differentiated)\\n\\nDepth of invasion:  pT4b - direct invasion or adherence to local organs (bladder, ureters)\\n\\nPeritoneal surface involvement:  not identified\\n\\nTumour infiltrating lymphocytes: low density\\n\\nExcision Margins:\\nProximal:  clear\\nDistal:  clear\\nRadial:  involved\\nDonuts:  not received\\n\\nLymph nodes:\\nNumber positive:  0\\nTotal number:  7\\n\\n\\nIntramural vein invasion:  not identified\\n\\nExtramural vein invasion:  not identified\\n\\nSmall vessel (lymphatic) invasion:  not identified\\n\\nPerineural invasion:  focally present\\n\\nDistant metastases:  present (omentum)\\n\\nOther findings:\\nPolyps:  not present\\nPolyp adjacent to carcinoma:  not identified\\nRemote colon:  normal\\nOther:  nil\\n\\nTreatment effect:  N/A\\n\\nAncillary studies:\\n\\nMismatch repair enzymes, Immunostains:\\nMLH1: normal (positive staining)\\nPMS2: normal (positive staining)\\nMSH2: normal (positive staining)\\nMSH6: normal (positive staining)\\n\\nComment:\\nAbsence of staining for either MLH1, PMS2, MSH2 or MSH6 is associated with microsatellite instability phenotype (MSH-H), and may reflect the presence of a germline mutation or somatic inactivation of that mismatch repair enzyme.\\n\\nPositive staining of a carcinoma for MLH1,  PMS2,  MSH2  and MSH6 indicates a low likelihood of microsatellite instability phenotype.\\n\\nThe antibodies used are not fully characterised for routine diagnostic use. Results may be affected by storage and fixation of specimens, and should be interpreted in conjunction with other investigation, including MSI testing where possible.\\n\\nMicrosatellite instability (MSI):  not tested\\n\\nSynthesis/stage (AJCC/UICC TNM 7):\\n\\nTNM stage:  pT4b pN0 pM1b\\n\\nStage grouping:  IV B\\n\\nResidual tumour:  R2 (macroscopic involvement)\\n\\nE.  Histology shows infiltration of the wall of the right ureter and adjacent fibrofatty tissue by moderately differentiated mucinous adenocarcinoma.  The tumour is however not seen at the end of the specimen marked with a suture (presumed resection margin).\\n\\nF.  Histology shows very focally a small amount of acellular mucinous material on outer aspect of the distal left ureter consistent with focal involvement by mucinous adenocarcinoma.  The resection margin marked by the suture is however not involved.\\n\\nG.  No evidence of malignancy is seen in one lymph node.\\n\\nH.  No evidence of malignancy is seen in three lymph nodes.\\n\\n\\n\\nDIAGNOSIS\\nA.  PERITONEAL NODULE  -  NO EVIDENCE OF MALIGNANCY\\nB.  LYMPH NODE 1  -  NO EVIDENCE OF MALIGNANCY IN 1 NODE\\nC.  LYMPH NODE 2 -  NO EVIDENCE OF MALIGNANCY IN 1 NODE\\nD.  COLON, BLADDER, PROSTATE, OMENTUM -\\n-  MODERATELY DIFFERENTIATED RECTAL MUCINOUS ADENOCARCINOMA WITH\\nINVASION THROUGH MUSCULARIS PROPRIA INTO PERIRECTAL SOFT TISSUE.\\n-  INVOLVEMENT OF THE POSTERIOR CIRCUMFERENTIAL RESECTION MARGIN.\\n-  FIBROINFLAMMATORY ADHESIONS TO BLADDER AND PROSTATE.\\n- OTHER MARGINS ALL CLEAR\\n- METASTATIC DEPOSIT WITHIN OMENTUM\\n- pT4b pN0  pM1b R2 (STAGE GROUP IV B)\\nE.  DISTAL RIGHT URETER -  INVOLVED BY MUCINOUS ADENOCARCINOMA\\nF.  DISTAL LEFT URETER  -  FOCALLY INVOLVED BY MUCINOUS ADENOCARCINOMA\\nG.  PARA-AORTIC LYMPH NODE -  NO EVIDENCE OF MALIGNANCY IN 1 NODE\\nH.  COMMON ILIAC LYMPH NODE -  NO EVIDENCE OF MALIGNANCY IN 3 NODES\\n5/5/2068 nh\\nSUPPLEMENTARY REPORT:\\nThe slides of the original resection from 2066 have been reviewed for comparison (DHM Pathology 21846-15MP). This shows a moderately differentiated mucinous adenocarcinoma probably of appendix, with metastatic deposits to right pelvic wall and rectosigmoid colon. Morphology is identical to the current tumour - which is therefore re-classified as recurrent metastatic disease rather than as a new primary.\\n\\nAMENDED DIAGNOSIS:\\nD.  COLON, BLADDER, PROSTATE, OMENTUM -  METASTATIC MUCINOUS ADENOCARCINOMA INVOLVING RECTUM.\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(file_path_array[0], \"r\") as f:\n",
    "    File_text = f.read()\n",
    "File_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "790b7f02-c1a8-4829-a778-11f110c069c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'opendid_test/file18628.txt'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_array[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57528006-3017-43c8-8e05-f8d8968d6047",
   "metadata": {},
   "source": [
    "##### #適用於第二種樣式病歷"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7353d3e6-127d-44cb-a359-5cf37caa823b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Name': ('PHI: NULL', 'PHI: NULL', 'PHI: NULL', 'PHI:PATIENT')} PHI: NULL PHI:PATIENT\n"
     ]
    }
   ],
   "source": [
    "GetName=GT.GetName(File_text)\n",
    "print(GetName[0],GetName[1],GetName[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc953d28-3659-4827-a26c-0a9690502569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'IDnum': ('73C471159N', 8, 18, 'PHI:MEDICALRECORD')} (<re.Match object; span=(8, 18), match='73C471159N'>, '73C471159N', 8, 18) PHI:MEDICALRECORD\n"
     ]
    }
   ],
   "source": [
    "GetIDnum=GT.GetIDnum(File_text)\n",
    "print(GetIDnum[0],GetIDnum[1],GetIDnum[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ff13f79-1267-45a4-9b08-fd29a25d3ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'IDMnum': ('PHI: NULL', 'PHI: NULL', 'PHI: NULL', 'PHI:MEDICALRECORD')} (None, 'PHI: NULL', 'PHI: NULL', 'PHI: NULL') PHI:MEDICALRECORD\n",
      "{'SPR_no': ('73C471159N', 8, 18, 'PHI:MEDICALRECORD')} (<re.Match object; span=(8, 18), match='73C471159N'>, '73C471159N', 8, 18) PHI:MEDICALRECORD\n"
     ]
    }
   ],
   "source": [
    "GetIDMnum=GT.GetIDMnum(File_text)\n",
    "print(GetIDMnum[0],GetIDMnum[1],GetIDMnum[2])\n",
    "\n",
    "GetSPRno=GT.GetSPRno(File_text)\n",
    "print(GetSPRno[0],GetSPRno[1],GetSPRno[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69b04924-857c-45d7-96c4-5b4686267879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MRN_no': ('73147115', 27, 35, 'PHI:MEDICALRECORD')} (<re.Match object; span=(27, 35), match='73147115'>, '73147115', 27, 35) PHI:MEDICALRECORD\n"
     ]
    }
   ],
   "source": [
    "GetMRNNo=GT.GetMRNNo(File_text)\n",
    "print(GetMRNNo[0],GetMRNNo[1],GetMRNNo[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cea8836-3a37-4bab-b770-5b508a1802a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PATIENT': ('COLON, BLADDER', 1373, 1387, 'PHI:PATIENT')} COLON, BLADDER PHI:PATIENT\n"
     ]
    }
   ],
   "source": [
    "GetPatientname=GT.GetPatientname(File_text)\n",
    "print(GetPatientname[0],GetPatientname[1],GetPatientname[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22341595-26a6-44d3-9100-8713469a84d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DR': ('PHI: NULL', 'PHI: NULL', 'PHI: NULL', 'PHI:DOCTOR')} PHI: NULL PHI:DOCTOR\n"
     ]
    }
   ],
   "source": [
    "GetDRname=GT.GetDRname(File_text)\n",
    "print(GetDRname[0],GetDRname[1],GetDRname[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4f798fb-53ad-46e4-affc-511c48a754bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'D.O.B': ('PHI: NULL', 'PHI: NULL', 'PHI: NULL', 'PHI:DATE')} PHI: NULL PHI:DATE\n"
     ]
    }
   ],
   "source": [
    "GetDOBInf=GT.GetDOB(File_text)\n",
    "print(GetDOBInf[0],GetDOBInf[1],GetDOBInf[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a015de0e-8fb1-47ce-abef-eaa326789aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Collected': ('PHI: NULL', 'PHI: NULL', 'PHI: NULL', 'PHI:TIME')} PHI: NULL PHI:TIME\n"
     ]
    }
   ],
   "source": [
    "GetCollInf=GT.Collected_info(File_text)\n",
    "print(GetCollInf[0],GetCollInf[1],GetCollInf[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "166589b8-bd14-4107-959f-61e9521eaa41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Location': ('PHI: NULL', 'PHI: NULL', 'PHI: NULL', 'PHI:HOSPITAL')} PHI: NULL PHI:HOSPITAL\n"
     ]
    }
   ],
   "source": [
    "GetLocalInf=GT.Location_info(File_text)       \n",
    "print(GetLocalInf[0],GetLocalInf[1],GetLocalInf[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7543a898-2ddb-4734-a5d6-cdf294a39d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Site_name': ('SHELLHARBOUR HOSPITAL', 47, 68, 'PHI:HOSPITAL')} SHELLHARBOUR HOSPITAL PHI:HOSPITAL\n"
     ]
    }
   ],
   "source": [
    "GetSiteNameInf= GT.SiteName_info(File_text)         \n",
    "print(GetSiteNameInf[0],GetSiteNameInf[1],GetSiteNameInf[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0cc985-ec9a-45b4-a277-5bf333904ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a589d7f-b210-4afb-81e2-82844445d503",
   "metadata": {},
   "source": [
    "##### #適用於第三種樣式病歷"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07a09b44-3f86-4200-8f9e-aade456245a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PATIENT': ('COLON, BLADDER', 1373, 1387, 'PHI:PATIENT')} COLON, BLADDER PHI:PATIENT\n"
     ]
    }
   ],
   "source": [
    "GetPatientname=GT.GetPatientname(File_text)\n",
    "print(GetPatientname[0],GetPatientname[1],GetPatientname[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bed25b89-229a-4530-8f94-b24c6e7e7f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'FirstName': ('PHI: NULL', 'PHI: NULL', 'PHI: NULL', 'PHI:PATIENT')} PHI: NULL PHI:PATIENT\n"
     ]
    }
   ],
   "source": [
    "GetFirsname=GT.GetFirsname(File_text)\n",
    "print(GetFirsname[0],GetFirsname[1],GetFirsname[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f5e4f48-1c4b-46b0-a027-a71f854ac520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MiddleName': ('PHI: NULL', 'PHI: NULL', 'PHI: NULL', 'PHI:PATIENT')} PHI: NULL PHI:PATIENT\n"
     ]
    }
   ],
   "source": [
    "GetMiddlename=GT.GetMiddlename(File_text)\n",
    "print(GetMiddlename[0],GetMiddlename[1],GetMiddlename[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27d61174-d16c-4bfe-9fd0-da8975e96fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LastName': ('PHI: NULL', 'PHI: NULL', 'PHI: NULL', 'PHI:PATIENT')} PHI: NULL PHI:PATIENT\n"
     ]
    }
   ],
   "source": [
    "GetLastname=GT.GetLastname(File_text)\n",
    "print(GetLastname[0],GetLastname[1],GetLastname[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e37f644e-b799-4981-bf4a-4ee8b9bac105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Doctorname': ('PHI: NULL', 'PHI: NULL', 'PHI: NULL', 'PHI:DOCTOR')} PHI: NULL PHI:DOCTOR\n"
     ]
    }
   ],
   "source": [
    "GetDRname=GT.GetDoctorname(File_text)\n",
    "print(GetDRname[0],GetDRname[1],GetDRname[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85ff63d7-cc7b-4e7c-812e-f4ea0e77f39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SpecimenReceivedDate': ('PHI: NULL', 'PHI: NULL', 'PHI: NULL', 'PHI:TIME')} PHI: NULL PHI:TIME\n"
     ]
    }
   ],
   "source": [
    "GetCollected=GT.GetCollected(File_text)\n",
    "print(GetCollected[0],GetCollected[1],GetCollected[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c802a91a-468c-4da9-9517-4536543fdfb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DateOfBirth': ('PHI: NULL', 'PHI: NULL', 'PHI: NULL', 'PHI:DATE')} PHI: NULL PHI:DATE\n"
     ]
    }
   ],
   "source": [
    "GetDateOfBirth=GT.GetDateOfBirth(File_text)\n",
    "print(GetDateOfBirth[0],GetDateOfBirth[1],GetDateOfBirth[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9fac3bd4-a0d6-4965-8b97-80d1f187eee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MRN': ('PHI: NULL', 'PHI: NULL', 'PHI: NULL', 'PHI:MEDICALRECORD')} (None, 'PHI: NULL', 'PHI: NULL', 'PHI: NULL') PHI:MEDICALRECORD\n"
     ]
    }
   ],
   "source": [
    "GetMRN=GT.GetMRN(File_text)\n",
    "print(GetMRN[0],GetMRN[1],GetMRN[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "79927001-4dec-4802-ae4f-99c4edd559ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SPRID': ('PHI: NULL', 'PHI: NULL', 'PHI: NULL', 'PHI:MEDICALRECORD')} (None, 'PHI: NULL', 'PHI: NULL', 'PHI: NULL') PHI:MEDICALRECORD\n"
     ]
    }
   ],
   "source": [
    "GetSPRID=GT.GetSPRID(File_text)\n",
    "print(GetSPRID[0],GetSPRID[1],GetSPRID[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40d84e62-9237-4902-8fa2-3a38da223b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MRN': ('PHI: NULL', 'PHI: NULL', 'PHI: NULL', 'PHI:MEDICALRECORD')} (None, 'PHI: NULL', 'PHI: NULL', 'PHI: NULL') PHI:MEDICALRECORD\n"
     ]
    }
   ],
   "source": [
    "GetMRN=GT.GetMRN(File_text)\n",
    "print(GetMRN[0],GetMRN[1],GetMRN[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "930f6a16-b815-426b-bc47-188770aaa5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Sex': ('PHI: NULL', 'PHI: NULL', 'PHI: NULL', 'PHI:Sex')} PHI: NULL PHI:Sex\n"
     ]
    }
   ],
   "source": [
    "GetSexinfo=GT.Sex_info(File_text)\n",
    "print(GetSexinfo[0],GetSexinfo[1],GetSexinfo[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4427407d-7d6d-4e79-9a27-9964a74987e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Gender': ('PHI: NULL', 'PHI: NULL', 'PHI: NULL', 'PHI:Sex')} PHI: NULL PHI:Sex\n"
     ]
    }
   ],
   "source": [
    "GetGender=GT.GetGender(File_text)\n",
    "print(GetGender[0],GetGender[1],GetGender[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15e9f9ca-504a-4fcc-8849-2cc85086b1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SpecimenReceivedDate': ('PHI: NULL', 'PHI: NULL', 'PHI: NULL', 'PHI:TIME')} PHI: NULL PHI:TIME\n"
     ]
    }
   ],
   "source": [
    "GetCollected=GT.GetCollected(File_text)\n",
    "print(GetCollected[0],GetCollected[1],GetCollected[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "14fe55d9-7f15-4673-a9a2-6da968a07e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SiteName': ('PHI: NULL', 'PHI: NULL', 'PHI: NULL', 'PHI:HOSPITAL')} PHI: NULL PHI:HOSPITAL\n"
     ]
    }
   ],
   "source": [
    "GetSiteName=GT.GetSiteName(File_text)\n",
    "print(GetSiteName[0],GetSiteName[1],GetSiteName[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f4d571-117b-4a7e-b539-11de38858e4f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2. File Regedit Read Conetnt(自訂函式庫)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cdc25f1f-d09a-419d-a15a-222f1697677e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num=0\n",
    "series2_list_all=[]\n",
    "min_length = min(len(file_path_array), len(file_name_array))\n",
    "#print(min_length)\n",
    "for num in range(min_length):\n",
    "    file_path_dict={'FilePath':file_path_array[num]}\n",
    "    file_name_dict={'FileName':file_name_array[num]}        \n",
    "    #print(file_name_dict)        \n",
    "    #print(file_path_dict)\n",
    "    with open(file_path_array[num], \"r\") as f:\n",
    "        File_text = f.read()\n",
    "        # 在這裡可以對每個檔案的內容進行處理，例如呼叫函數 GT(File_text) 處理內容\n",
    "        GT(File_text)\n",
    "        # GetPtInf=GT.GetPatientInfo(File_text)\n",
    "        GetName=GT.GetName(File_text)\n",
    "        GetIDnum=GT.GetIDnum(File_text)\n",
    "        GetIDMnum=GT.GetIDMnum(File_text)\n",
    "        GetSPRno=GT.GetSPRno(File_text)\n",
    "        GetMRNNo=GT.GetMRNNo(File_text)\n",
    "        GetPatientname=GT.GetPatientname(File_text)\n",
    "        GetDRname=GT.GetDRname(File_text)\n",
    "        GetDOBInf=GT.GetDOB(File_text)\n",
    "        GetCollInf=GT.Collected_info(File_text)\n",
    "        GetLocalInf=GT.Location_info(File_text)       \n",
    "        GetSiteNameInf= GT.SiteName_info(File_text)\n",
    "        GetSexinfo=GT.Sex_info(File_text)        \n",
    "        merged_dict = {**file_name_dict,**file_path_dict,**GetName[0],**GetIDnum[0],**GetIDMnum[0],**GetSPRno[0],**GetMRNNo[0],**GetPatientname[0],**GetDRname[0],**GetDOBInf[0],**GetCollInf[0],**GetLocalInf[0],**GetSiteNameInf[0],**GetSexinfo[0]}        \n",
    "        series2_list_all.append(pd.Series(merged_dict))  # 将 merged_dict 添加到 series_list_all 中        \n",
    "        num+=1\n",
    "DF_ALL_Stytle2 = pd.concat(series2_list_all, axis=1).transpose()  # 合并所有的 merged_dict，并创建 DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b33df8-bde3-487c-a4f6-2675c0345aec",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3. DataFrame to_CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f948622-1691-4be7-b7ea-7c2eef351a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 473 entries, 0 to 472\n",
      "Data columns (total 14 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   FileName   473 non-null    object\n",
      " 1   FilePath   473 non-null    object\n",
      " 2   Name       473 non-null    object\n",
      " 3   IDnum      473 non-null    object\n",
      " 4   IDMnum     473 non-null    object\n",
      " 5   SPR_no     473 non-null    object\n",
      " 6   MRN_no     473 non-null    object\n",
      " 7   PATIENT    473 non-null    object\n",
      " 8   DR         473 non-null    object\n",
      " 9   D.O.B      473 non-null    object\n",
      " 10  Collected  473 non-null    object\n",
      " 11  Location   473 non-null    object\n",
      " 12  Site_name  473 non-null    object\n",
      " 13  Sex        473 non-null    object\n",
      "dtypes: object(14)\n",
      "memory usage: 51.9+ KB\n"
     ]
    }
   ],
   "source": [
    "DF_ALL_Stytle2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4bc478f3-e7d9-4e3c-9a2b-7582035fd316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileName                                             file18628\n",
       "FilePath                            opendid_test/file18628.txt\n",
       "Name            (PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)\n",
       "IDnum                   (73C471159N, 8, 18, PHI:MEDICALRECORD)\n",
       "IDMnum       (PHI: NULL, PHI: NULL, PHI: NULL, PHI:MEDICALR...\n",
       "SPR_no                  (73C471159N, 8, 18, PHI:MEDICALRECORD)\n",
       "MRN_no                   (73147115, 27, 35, PHI:MEDICALRECORD)\n",
       "PATIENT              (COLON, BLADDER, 1373, 1387, PHI:PATIENT)\n",
       "DR               (PHI: NULL, PHI: NULL, PHI: NULL, PHI:DOCTOR)\n",
       "D.O.B              (PHI: NULL, PHI: NULL, PHI: NULL, PHI:DATE)\n",
       "Collected          (PHI: NULL, PHI: NULL, PHI: NULL, PHI:TIME)\n",
       "Location       (PHI: NULL, PHI: NULL, PHI: NULL, PHI:HOSPITAL)\n",
       "Site_name        (SHELLHARBOUR HOSPITAL, 47, 68, PHI:HOSPITAL)\n",
       "Sex                 (PHI: NULL, PHI: NULL, PHI: NULL, PHI:Sex)\n",
       "dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series2_list_all[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0ba61291-ac2c-4854-9658-19c590d28d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_Stytle2_rows=DF_ALL_Stytle2[['FileName','FilePath','PATIENT','Name','IDnum','IDMnum','SPR_no','MRN_no','DR','D.O.B','Collected','Location','Site_name','Sex']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "28b06aad-317f-4319-9294-e73d1e1be85b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileName</th>\n",
       "      <th>FilePath</th>\n",
       "      <th>PATIENT</th>\n",
       "      <th>Name</th>\n",
       "      <th>IDnum</th>\n",
       "      <th>IDMnum</th>\n",
       "      <th>SPR_no</th>\n",
       "      <th>MRN_no</th>\n",
       "      <th>DR</th>\n",
       "      <th>D.O.B</th>\n",
       "      <th>Collected</th>\n",
       "      <th>Location</th>\n",
       "      <th>Site_name</th>\n",
       "      <th>Sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>file18628</td>\n",
       "      <td>opendid_test/file18628.txt</td>\n",
       "      <td>(COLON, BLADDER, 1373, 1387, PHI:PATIENT)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)</td>\n",
       "      <td>(73C471159N, 8, 18, PHI:MEDICALRECORD)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:MEDICALR...</td>\n",
       "      <td>(73C471159N, 8, 18, PHI:MEDICALRECORD)</td>\n",
       "      <td>(73147115, 27, 35, PHI:MEDICALRECORD)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:DOCTOR)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:DATE)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:TIME)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:HOSPITAL)</td>\n",
       "      <td>(SHELLHARBOUR HOSPITAL, 47, 68, PHI:HOSPITAL)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:Sex)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>file22002</td>\n",
       "      <td>opendid_test/file22002.txt</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)</td>\n",
       "      <td>(78D911317T, 84, 94, PHI:MEDICALRECORD)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:MEDICALR...</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:MEDICALR...</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:MEDICALR...</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:DOCTOR)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:DATE)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:TIME)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:HOSPITAL)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:HOSPITAL)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:Sex)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>file30867</td>\n",
       "      <td>opendid_test/file30867.txt</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)</td>\n",
       "      <td>(00M113124Q, 8, 18, PHI:MEDICALRECORD)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:MEDICALR...</td>\n",
       "      <td>(00M113124Q, 8, 18, PHI:MEDICALRECORD)</td>\n",
       "      <td>(00411312, 27, 35, PHI:MEDICALRECORD)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:DOCTOR)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:DATE)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:TIME)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:HOSPITAL)</td>\n",
       "      <td>(CULCAIRN MULTI PURPOSE SERVICE HOSPITAL, 47, ...</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:Sex)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>file30890</td>\n",
       "      <td>opendid_test/file30890.txt</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)</td>\n",
       "      <td>(68I134282Y, 8, 18, PHI:MEDICALRECORD)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:MEDICALR...</td>\n",
       "      <td>(68I134282Y, 8, 18, PHI:MEDICALRECORD)</td>\n",
       "      <td>(6831342, 27, 34, PHI:MEDICALRECORD)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:DOCTOR)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:DATE)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:TIME)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:HOSPITAL)</td>\n",
       "      <td>(GLADSTONE HOSPITAL, 46, 64, PHI:HOSPITAL)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:Sex)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>file30914</td>\n",
       "      <td>opendid_test/file30914.txt</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)</td>\n",
       "      <td>(53J684440E, 8, 18, PHI:MEDICALRECORD)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:MEDICALR...</td>\n",
       "      <td>(53J684440E, 8, 18, PHI:MEDICALRECORD)</td>\n",
       "      <td>(533684, 27, 33, PHI:MEDICALRECORD)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:DOCTOR)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:DATE)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:TIME)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:HOSPITAL)</td>\n",
       "      <td>(TEMORA HOSPITAL, 45, 60, PHI:HOSPITAL)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:Sex)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>file30951</td>\n",
       "      <td>opendid_test/file30951.txt</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)</td>\n",
       "      <td>(95S886257B, 8, 18, PHI:MEDICALRECORD)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:MEDICALR...</td>\n",
       "      <td>(95S886257B, 8, 18, PHI:MEDICALRECORD)</td>\n",
       "      <td>(9568862, 27, 34, PHI:MEDICALRECORD)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:DOCTOR)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:DATE)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:TIME)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:HOSPITAL)</td>\n",
       "      <td>(FLINDERS ISLAND MULTI PURPOSE CENTRE, 46, 82,...</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:Sex)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>file30997</td>\n",
       "      <td>opendid_test/file30997.txt</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)</td>\n",
       "      <td>(53O907215K, 8, 18, PHI:MEDICALRECORD)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:MEDICALR...</td>\n",
       "      <td>(53O907215K, 8, 18, PHI:MEDICALRECORD)</td>\n",
       "      <td>(5359072, 27, 34, PHI:MEDICALRECORD)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:DOCTOR)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:DATE)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:TIME)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:HOSPITAL)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:HOSPITAL)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:Sex)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>file31047</td>\n",
       "      <td>opendid_test/file31047.txt</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)</td>\n",
       "      <td>(48P347573Q, 8, 18, PHI:MEDICALRECORD)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:MEDICALR...</td>\n",
       "      <td>(48P347573Q, 8, 18, PHI:MEDICALRECORD)</td>\n",
       "      <td>(4853475, 27, 34, PHI:MEDICALRECORD)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:DOCTOR)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:DATE)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:TIME)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:HOSPITAL)</td>\n",
       "      <td>(KOOWEERUP REGIONAL HEALTH SERVICE, 46, 79, PH...</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:Sex)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>file31088</td>\n",
       "      <td>opendid_test/file31088.txt</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)</td>\n",
       "      <td>(80Y549289M, 8, 18, PHI:MEDICALRECORD)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:MEDICALR...</td>\n",
       "      <td>(80Y549289M, 8, 18, PHI:MEDICALRECORD)</td>\n",
       "      <td>(80954928, 27, 35, PHI:MEDICALRECORD)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:DOCTOR)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:DATE)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:TIME)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:HOSPITAL)</td>\n",
       "      <td>(LIVERPOOL HOSPITAL, 47, 65, PHI:HOSPITAL)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:Sex)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>file31154</td>\n",
       "      <td>opendid_test/file31154.txt</td>\n",
       "      <td>(INCORRECTLY, SHOULD, 401, 420, PHI:PATIENT)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)</td>\n",
       "      <td>(38U660338V, 8, 18, PHI:MEDICALRECORD)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:MEDICALR...</td>\n",
       "      <td>(38U660338V, 8, 18, PHI:MEDICALRECORD)</td>\n",
       "      <td>(3876603, 27, 34, PHI:MEDICALRECORD)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:DOCTOR)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:DATE)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:TIME)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:HOSPITAL)</td>\n",
       "      <td>(SOUTH GIPPSLAND HOSPITAL, 46, 70, PHI:HOSPITAL)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:Sex)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    FileName                    FilePath  \\\n",
       "0  file18628  opendid_test/file18628.txt   \n",
       "1  file22002  opendid_test/file22002.txt   \n",
       "2  file30867  opendid_test/file30867.txt   \n",
       "3  file30890  opendid_test/file30890.txt   \n",
       "4  file30914  opendid_test/file30914.txt   \n",
       "5  file30951  opendid_test/file30951.txt   \n",
       "6  file30997  opendid_test/file30997.txt   \n",
       "7  file31047  opendid_test/file31047.txt   \n",
       "8  file31088  opendid_test/file31088.txt   \n",
       "9  file31154  opendid_test/file31154.txt   \n",
       "\n",
       "                                          PATIENT  \\\n",
       "0       (COLON, BLADDER, 1373, 1387, PHI:PATIENT)   \n",
       "1  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)   \n",
       "2  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)   \n",
       "3  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)   \n",
       "4  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)   \n",
       "5  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)   \n",
       "6  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)   \n",
       "7  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)   \n",
       "8  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)   \n",
       "9    (INCORRECTLY, SHOULD, 401, 420, PHI:PATIENT)   \n",
       "\n",
       "                                             Name  \\\n",
       "0  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)   \n",
       "1  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)   \n",
       "2  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)   \n",
       "3  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)   \n",
       "4  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)   \n",
       "5  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)   \n",
       "6  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)   \n",
       "7  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)   \n",
       "8  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)   \n",
       "9  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)   \n",
       "\n",
       "                                     IDnum  \\\n",
       "0   (73C471159N, 8, 18, PHI:MEDICALRECORD)   \n",
       "1  (78D911317T, 84, 94, PHI:MEDICALRECORD)   \n",
       "2   (00M113124Q, 8, 18, PHI:MEDICALRECORD)   \n",
       "3   (68I134282Y, 8, 18, PHI:MEDICALRECORD)   \n",
       "4   (53J684440E, 8, 18, PHI:MEDICALRECORD)   \n",
       "5   (95S886257B, 8, 18, PHI:MEDICALRECORD)   \n",
       "6   (53O907215K, 8, 18, PHI:MEDICALRECORD)   \n",
       "7   (48P347573Q, 8, 18, PHI:MEDICALRECORD)   \n",
       "8   (80Y549289M, 8, 18, PHI:MEDICALRECORD)   \n",
       "9   (38U660338V, 8, 18, PHI:MEDICALRECORD)   \n",
       "\n",
       "                                              IDMnum  \\\n",
       "0  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:MEDICALR...   \n",
       "1  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:MEDICALR...   \n",
       "2  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:MEDICALR...   \n",
       "3  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:MEDICALR...   \n",
       "4  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:MEDICALR...   \n",
       "5  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:MEDICALR...   \n",
       "6  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:MEDICALR...   \n",
       "7  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:MEDICALR...   \n",
       "8  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:MEDICALR...   \n",
       "9  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:MEDICALR...   \n",
       "\n",
       "                                              SPR_no  \\\n",
       "0             (73C471159N, 8, 18, PHI:MEDICALRECORD)   \n",
       "1  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:MEDICALR...   \n",
       "2             (00M113124Q, 8, 18, PHI:MEDICALRECORD)   \n",
       "3             (68I134282Y, 8, 18, PHI:MEDICALRECORD)   \n",
       "4             (53J684440E, 8, 18, PHI:MEDICALRECORD)   \n",
       "5             (95S886257B, 8, 18, PHI:MEDICALRECORD)   \n",
       "6             (53O907215K, 8, 18, PHI:MEDICALRECORD)   \n",
       "7             (48P347573Q, 8, 18, PHI:MEDICALRECORD)   \n",
       "8             (80Y549289M, 8, 18, PHI:MEDICALRECORD)   \n",
       "9             (38U660338V, 8, 18, PHI:MEDICALRECORD)   \n",
       "\n",
       "                                              MRN_no  \\\n",
       "0              (73147115, 27, 35, PHI:MEDICALRECORD)   \n",
       "1  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:MEDICALR...   \n",
       "2              (00411312, 27, 35, PHI:MEDICALRECORD)   \n",
       "3               (6831342, 27, 34, PHI:MEDICALRECORD)   \n",
       "4                (533684, 27, 33, PHI:MEDICALRECORD)   \n",
       "5               (9568862, 27, 34, PHI:MEDICALRECORD)   \n",
       "6               (5359072, 27, 34, PHI:MEDICALRECORD)   \n",
       "7               (4853475, 27, 34, PHI:MEDICALRECORD)   \n",
       "8              (80954928, 27, 35, PHI:MEDICALRECORD)   \n",
       "9               (3876603, 27, 34, PHI:MEDICALRECORD)   \n",
       "\n",
       "                                              DR  \\\n",
       "0  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:DOCTOR)   \n",
       "1  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:DOCTOR)   \n",
       "2  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:DOCTOR)   \n",
       "3  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:DOCTOR)   \n",
       "4  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:DOCTOR)   \n",
       "5  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:DOCTOR)   \n",
       "6  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:DOCTOR)   \n",
       "7  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:DOCTOR)   \n",
       "8  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:DOCTOR)   \n",
       "9  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:DOCTOR)   \n",
       "\n",
       "                                         D.O.B  \\\n",
       "0  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:DATE)   \n",
       "1  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:DATE)   \n",
       "2  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:DATE)   \n",
       "3  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:DATE)   \n",
       "4  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:DATE)   \n",
       "5  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:DATE)   \n",
       "6  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:DATE)   \n",
       "7  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:DATE)   \n",
       "8  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:DATE)   \n",
       "9  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:DATE)   \n",
       "\n",
       "                                     Collected  \\\n",
       "0  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:TIME)   \n",
       "1  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:TIME)   \n",
       "2  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:TIME)   \n",
       "3  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:TIME)   \n",
       "4  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:TIME)   \n",
       "5  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:TIME)   \n",
       "6  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:TIME)   \n",
       "7  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:TIME)   \n",
       "8  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:TIME)   \n",
       "9  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:TIME)   \n",
       "\n",
       "                                          Location  \\\n",
       "0  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:HOSPITAL)   \n",
       "1  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:HOSPITAL)   \n",
       "2  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:HOSPITAL)   \n",
       "3  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:HOSPITAL)   \n",
       "4  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:HOSPITAL)   \n",
       "5  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:HOSPITAL)   \n",
       "6  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:HOSPITAL)   \n",
       "7  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:HOSPITAL)   \n",
       "8  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:HOSPITAL)   \n",
       "9  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:HOSPITAL)   \n",
       "\n",
       "                                           Site_name  \\\n",
       "0      (SHELLHARBOUR HOSPITAL, 47, 68, PHI:HOSPITAL)   \n",
       "1    (PHI: NULL, PHI: NULL, PHI: NULL, PHI:HOSPITAL)   \n",
       "2  (CULCAIRN MULTI PURPOSE SERVICE HOSPITAL, 47, ...   \n",
       "3         (GLADSTONE HOSPITAL, 46, 64, PHI:HOSPITAL)   \n",
       "4            (TEMORA HOSPITAL, 45, 60, PHI:HOSPITAL)   \n",
       "5  (FLINDERS ISLAND MULTI PURPOSE CENTRE, 46, 82,...   \n",
       "6    (PHI: NULL, PHI: NULL, PHI: NULL, PHI:HOSPITAL)   \n",
       "7  (KOOWEERUP REGIONAL HEALTH SERVICE, 46, 79, PH...   \n",
       "8         (LIVERPOOL HOSPITAL, 47, 65, PHI:HOSPITAL)   \n",
       "9   (SOUTH GIPPSLAND HOSPITAL, 46, 70, PHI:HOSPITAL)   \n",
       "\n",
       "                                          Sex  \n",
       "0  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:Sex)  \n",
       "1  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:Sex)  \n",
       "2  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:Sex)  \n",
       "3  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:Sex)  \n",
       "4  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:Sex)  \n",
       "5  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:Sex)  \n",
       "6  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:Sex)  \n",
       "7  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:Sex)  \n",
       "8  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:Sex)  \n",
       "9  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:Sex)  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_Stytle2_rows.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b251cb6b-5824-4e44-92a0-1f4f4fe661f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将DataFrame保存为CSV文件\n",
    "selected_Stytle2_rows.to_csv('Stytle2_Content.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "106f91f7-64c1-4d89-86b2-6beb66454b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "num=0\n",
    "series3_list_all=[]\n",
    "min_length = min(len(file_path_array), len(file_name_array))\n",
    "#print(min_length)\n",
    "for num in range(min_length):\n",
    "    file_path_dict={'FilePath':file_path_array[num]}\n",
    "    file_name_dict={'FileName':file_name_array[num]}        \n",
    "    #print(file_name_dict)        \n",
    "    #print(file_path_dict)\n",
    "    with open(file_path_array[num], \"r\") as f:\n",
    "        File_text = f.read()\n",
    "        # 在這裡可以對每個檔案的內容進行處理，例如呼叫函數 GT(File_text) 處理內容\n",
    "        GT(File_text)       \n",
    "        GetPatientname=GT.GetPatientname(File_text)\n",
    "        GetFirsname=GT.GetFirsname(File_text)\n",
    "        GetMiddlename=GT.GetMiddlename(File_text)\n",
    "        GetLastname=GT.GetLastname(File_text)\n",
    "        GetMRN=GT.GetMRN(File_text)        \n",
    "        GetSPRID=GT.GetSPRID(File_text)        \n",
    "        GetDRname=GT.GetDoctorname(File_text)\n",
    "        # GetDateOfBirth=GT.GetDateOfBirth(File_text)        \n",
    "        GetCollected=GT.GetCollected(File_text)                      \n",
    "        GetSiteName=GT.GetSiteName(File_text)        \n",
    "        GetGender=GT.GetGender(File_text)        \n",
    "        merged_dict = {**file_name_dict,**file_path_dict,**GetPatientname[0],**GetFirsname[0],**GetMiddlename[0],**GetLastname[0],**GetDRname[0],**GetCollected[0],**GetCollInf[0],**GetMRN[0],**GetLocalInf[0],**GetSiteName[0],**GetSPRID[0],**GetGender[0]}        \n",
    "        series3_list_all.append(pd.Series(merged_dict))  # 将 merged_dict 添加到 series_list_all 中        \n",
    "        num+=1\n",
    "DF_ALL_Stytle3 = pd.concat(series3_list_all, axis=1).transpose()  # 合并所有的 merged_dict，并创建 DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ac991e4f-3667-47bc-a49f-1c57c5d144e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 473 entries, 0 to 472\n",
      "Data columns (total 14 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   FileName              473 non-null    object\n",
      " 1   FilePath              473 non-null    object\n",
      " 2   PATIENT               473 non-null    object\n",
      " 3   FirstName             473 non-null    object\n",
      " 4   MiddleName            473 non-null    object\n",
      " 5   LastName              473 non-null    object\n",
      " 6   Doctorname            473 non-null    object\n",
      " 7   SpecimenReceivedDate  473 non-null    object\n",
      " 8   Collected             473 non-null    object\n",
      " 9   MRN                   473 non-null    object\n",
      " 10  Location              473 non-null    object\n",
      " 11  SiteName              473 non-null    object\n",
      " 12  SPRID                 473 non-null    object\n",
      " 13  Gender                473 non-null    object\n",
      "dtypes: object(14)\n",
      "memory usage: 51.9+ KB\n"
     ]
    }
   ],
   "source": [
    "DF_ALL_Stytle3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8ae7f08a-9676-4dcc-9550-0f0f2a9379ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_Stytle3_rows=DF_ALL_Stytle3[['FileName','FilePath','PATIENT','FirstName','MiddleName','LastName','Doctorname','SpecimenReceivedDate','Collected','MRN','Location','SiteName','SPRID','Gender']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "37152405-7cee-45d8-8113-f328bccee4b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileName</th>\n",
       "      <th>FilePath</th>\n",
       "      <th>PATIENT</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>MiddleName</th>\n",
       "      <th>LastName</th>\n",
       "      <th>Doctorname</th>\n",
       "      <th>SpecimenReceivedDate</th>\n",
       "      <th>Collected</th>\n",
       "      <th>MRN</th>\n",
       "      <th>Location</th>\n",
       "      <th>SiteName</th>\n",
       "      <th>SPRID</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>file18628</td>\n",
       "      <td>opendid_test/file18628.txt</td>\n",
       "      <td>(COLON, BLADDER, 1373, 1387, PHI:PATIENT)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:DOCTOR)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:TIME)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:TIME)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:MEDICALR...</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:HOSPITAL)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:HOSPITAL)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:MEDICALR...</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:Sex)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>file22002</td>\n",
       "      <td>opendid_test/file22002.txt</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)</td>\n",
       "      <td>(Jask, 70, 74, PHI:PATIENT)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)</td>\n",
       "      <td>(William, 6202, 6209, PHI:PATIENT)</td>\n",
       "      <td>( (Dr. S. Zonker), PHI: NULL, PHI: NULL, PHI:D...</td>\n",
       "      <td>(2072-04-21 00:00:00, 6171, 6190, PHI:TIME)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:TIME)</td>\n",
       "      <td>(7819113, 101, 108, PHI:MEDICALRECORD)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:HOSPITAL)</td>\n",
       "      <td>(CAMPBELLTOWN HOSPITAL, 36, 57, PHI:HOSPITAL)</td>\n",
       "      <td>(78D911317T, 84, 94, PHI:MEDICALRECORD)</td>\n",
       "      <td>(M, 38, 39, PHI:Sex)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>file30867</td>\n",
       "      <td>opendid_test/file30867.txt</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:DOCTOR)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:TIME)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:TIME)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:MEDICALR...</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:HOSPITAL)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:HOSPITAL)</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:MEDICALR...</td>\n",
       "      <td>(PHI: NULL, PHI: NULL, PHI: NULL, PHI:Sex)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    FileName                    FilePath  \\\n",
       "0  file18628  opendid_test/file18628.txt   \n",
       "1  file22002  opendid_test/file22002.txt   \n",
       "2  file30867  opendid_test/file30867.txt   \n",
       "\n",
       "                                          PATIENT  \\\n",
       "0       (COLON, BLADDER, 1373, 1387, PHI:PATIENT)   \n",
       "1  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)   \n",
       "2  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)   \n",
       "\n",
       "                                        FirstName  \\\n",
       "0  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)   \n",
       "1                     (Jask, 70, 74, PHI:PATIENT)   \n",
       "2  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)   \n",
       "\n",
       "                                       MiddleName  \\\n",
       "0  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)   \n",
       "1  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)   \n",
       "2  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)   \n",
       "\n",
       "                                         LastName  \\\n",
       "0  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)   \n",
       "1              (William, 6202, 6209, PHI:PATIENT)   \n",
       "2  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:PATIENT)   \n",
       "\n",
       "                                          Doctorname  \\\n",
       "0      (PHI: NULL, PHI: NULL, PHI: NULL, PHI:DOCTOR)   \n",
       "1  ( (Dr. S. Zonker), PHI: NULL, PHI: NULL, PHI:D...   \n",
       "2      (PHI: NULL, PHI: NULL, PHI: NULL, PHI:DOCTOR)   \n",
       "\n",
       "                          SpecimenReceivedDate  \\\n",
       "0  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:TIME)   \n",
       "1  (2072-04-21 00:00:00, 6171, 6190, PHI:TIME)   \n",
       "2  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:TIME)   \n",
       "\n",
       "                                     Collected  \\\n",
       "0  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:TIME)   \n",
       "1  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:TIME)   \n",
       "2  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:TIME)   \n",
       "\n",
       "                                                 MRN  \\\n",
       "0  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:MEDICALR...   \n",
       "1             (7819113, 101, 108, PHI:MEDICALRECORD)   \n",
       "2  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:MEDICALR...   \n",
       "\n",
       "                                          Location  \\\n",
       "0  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:HOSPITAL)   \n",
       "1  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:HOSPITAL)   \n",
       "2  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:HOSPITAL)   \n",
       "\n",
       "                                          SiteName  \\\n",
       "0  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:HOSPITAL)   \n",
       "1    (CAMPBELLTOWN HOSPITAL, 36, 57, PHI:HOSPITAL)   \n",
       "2  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:HOSPITAL)   \n",
       "\n",
       "                                               SPRID  \\\n",
       "0  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:MEDICALR...   \n",
       "1            (78D911317T, 84, 94, PHI:MEDICALRECORD)   \n",
       "2  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:MEDICALR...   \n",
       "\n",
       "                                       Gender  \n",
       "0  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:Sex)  \n",
       "1                        (M, 38, 39, PHI:Sex)  \n",
       "2  (PHI: NULL, PHI: NULL, PHI: NULL, PHI:Sex)  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_Stytle3_rows.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "86c9d571-8303-4604-bfd3-998138fc8381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将DataFrame保存为CSV文件\n",
    "selected_Stytle3_rows.to_csv('Stytle3_Content.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea616c8-1bf9-46da-a92d-b539c8a23d2a",
   "metadata": {},
   "source": [
    "## 4.資料格式轉換"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b55b389-ed8d-4b4a-8e74-a30157c28440",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 4.1 檢查欄位資訊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "836a26be-6802-498d-b32a-a4728965f86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 473 entries, 0 to 472\n",
      "Data columns (total 14 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   FileName   473 non-null    object\n",
      " 1   FilePath   473 non-null    object\n",
      " 2   Name       473 non-null    object\n",
      " 3   IDnum      473 non-null    object\n",
      " 4   IDMnum     473 non-null    object\n",
      " 5   SPR_no     473 non-null    object\n",
      " 6   MRN_no     473 non-null    object\n",
      " 7   PATIENT    473 non-null    object\n",
      " 8   DR         473 non-null    object\n",
      " 9   D.O.B      473 non-null    object\n",
      " 10  Collected  473 non-null    object\n",
      " 11  Location   473 non-null    object\n",
      " 12  Site_name  473 non-null    object\n",
      " 13  Sex        473 non-null    object\n",
      "dtypes: object(14)\n",
      "memory usage: 51.9+ KB\n"
     ]
    }
   ],
   "source": [
    "DF_ALL_Stytle2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b4efe8b9-d6e4-41cb-8ac1-c46d4c12d671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 473 entries, 0 to 472\n",
      "Data columns (total 14 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   FileName              473 non-null    object\n",
      " 1   FilePath              473 non-null    object\n",
      " 2   PATIENT               473 non-null    object\n",
      " 3   FirstName             473 non-null    object\n",
      " 4   MiddleName            473 non-null    object\n",
      " 5   LastName              473 non-null    object\n",
      " 6   Doctorname            473 non-null    object\n",
      " 7   SpecimenReceivedDate  473 non-null    object\n",
      " 8   Collected             473 non-null    object\n",
      " 9   MRN                   473 non-null    object\n",
      " 10  Location              473 non-null    object\n",
      " 11  SiteName              473 non-null    object\n",
      " 12  SPRID                 473 non-null    object\n",
      " 13  Gender                473 non-null    object\n",
      "dtypes: object(14)\n",
      "memory usage: 51.9+ KB\n"
     ]
    }
   ],
   "source": [
    "DF_ALL_Stytle3.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c02472c-a680-4271-8295-4baaaec8e954",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 4.2 自訂DOB時間格式字符串轉換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e0431100-dfbf-4c96-ada2-8fa08ba56fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 自定义函数来执行 to_datetime 转换\n",
    "def BOD_to_datetime(value):\n",
    "    if value == 'PHI: NULL':\n",
    "        return value\n",
    "    else:\n",
    "        return pd.to_datetime(value, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "94b4921e-b45d-42c7-baa6-bb743515d609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 自定义函数来执行 to_datetime 转换\n",
    "def DOB_Tdatetime(value):\n",
    "    if value == 'PHI: NULL':\n",
    "        return value\n",
    "    else:\n",
    "        date_reg = r\"(\\d{1,2}/\\d{1,2}/\\d{4})\"   \n",
    "        date_match = re.search(date_reg, value)\n",
    "        date_str=date_match.group(1).strip()\n",
    "        # 定义日期时间格式字符串\n",
    "        date_format = \"%d/%m/%Y\"        \n",
    "        # 解析时间字符串\n",
    "        parsed_time = datetime.strptime(date_str, date_format)        \n",
    "        # 格式化为所需的输出格式\n",
    "        # formatted_time = parsed_time.strftime(\"%Y-%m-%dT%H:%M\")\n",
    "        formatted_time = parsed_time.strftime(\"%Y-%m-%d\")        \n",
    "        return formatted_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10155da0-6cf9-4567-ad17-cdaaab64b647",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 4.3 自訂Collected時間格式字符串轉換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ecb3842d-3577-47d4-82c4-5b18617756e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "69ef89ab-7226-4e9c-97b8-ac9ff3d98915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义函数来执行 to_datetime 转换\n",
    "def Collected_Tdatetime(value):\n",
    "    if value == 'PHI: NULL':\n",
    "        return value\n",
    "    else:\n",
    "        # 定义两种可能的日期时间格式\n",
    "        date_format1 = r\"(\\d{1,2}/\\d{1,2}/\\d{4}) at (\\d{1,2}:\\d{1,2})\"\n",
    "        date_format2 = r\"(\\d{1,2}/\\d{1,2}/\\d{4}) at :\"\n",
    "        match1 = re.search(date_format1, value)\n",
    "        match2 = re.search(date_format2, value)\n",
    "        if match1:\n",
    "            date_str = match1.group(1)\n",
    "            time_str = match1.group(2)\n",
    "            formatted_time = f\"{date_str} at {time_str}\"            \n",
    "            parsed_time = datetime.strptime(f\"{date_str} at {time_str}\", \"%d/%m/%Y at %H:%M\")\n",
    "            formatted_time = parsed_time.strftime(\"%Y-%m-%dT%H:%M\")\n",
    "        elif match2:          \n",
    "            date_str = match2.group(1)\n",
    "            formatted_time = date_str          \n",
    "            parsed_time = datetime.strptime(f\"{date_str} at : \", \"%d/%m/%Y at : \")\n",
    "            formatted_time = parsed_time.strftime(\"%Y-%m-%d\")   \n",
    "        else:\n",
    "            return \"PHI:NULL\"                \n",
    "        return formatted_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ddf6f9-9af6-41b4-ae0f-5b62af3e7a45",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 4.4 自訂時間格式保留年月日轉換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "993421b4-9fb6-4250-8fbd-b4ac78d576d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 自定义函数来执行 to_datetime 转换\n",
    "def Tdatetime(value):\n",
    "    if value != 'PHI: NULL':\n",
    "        date_reg = r\"(\\d{4}-\\d{1,2}-\\d{1,2}) (\\d{1,2}:\\d{1,2})\"   \n",
    "        date_match = re.search(date_reg, value)\n",
    "        if date_match !=None:\n",
    "            date_str=date_match.group(1).strip()\n",
    "            date_format = \"%Y-%m-%d\"        \n",
    "            # 解析时间字符串\n",
    "            parsed_time = datetime.strptime(date_str, date_format)        \n",
    "            # 格式化为所需的输出格式\n",
    "            formatted_time = parsed_time.strftime(\"%Y-%m-%d\")        \n",
    "            return formatted_time\n",
    "    else:\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "62d534cc-d5d0-4d67-a674-662eb816fd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2_Collected= selected_Stytle2_rows[['FileName','Collected']]\n",
    "# data2_Collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ef2befe8-7ba9-4291-ae99-a8b25c5c8c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data3_Collected= selected_Stytle3_rows[['FileName','Collected']]\n",
    "# data3_Collected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4110a2-27cf-467a-b212-969757c967d4",
   "metadata": {},
   "source": [
    "## 5.資料匯出成answer.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93f1eb4-d778-442e-b157-c57673d5fc76",
   "metadata": {},
   "source": [
    "#### 樣式2查詢結果匯出"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ec16ab-7e0f-458a-8987-88380ff5d692",
   "metadata": {},
   "source": [
    "##### 5.1 PATIENT資料匯出_樣式2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a5003ac0-7dad-4c11-ac7e-f7859954cc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有 STREET 内容已保存到 answer.txt 文件中。\n"
     ]
    }
   ],
   "source": [
    "data_PATIENT= selected_Stytle2_rows[['FileName','Name']]\n",
    "# 初始化一个空的字符串，用于累积 STREET 数据\n",
    "all_PATIENT_data = \"\"\n",
    "# 遍历每一行并处理数据\n",
    "for index, row in data_PATIENT.iterrows():\n",
    "    FileName, PATIENT_data = row['FileName'], row['Name']\n",
    "    # 如果 STREET 数据不为空\n",
    "    if not pd.isnull(PATIENT_data):\n",
    "        PATIENT_content, start_position, end_position, phi_content = PATIENT_data\n",
    "        if start_position != 'PHI: NULL':        \n",
    "            # 去除 \"PHI:\" 文字\n",
    "            phi_content = phi_content.replace(\"PHI:\", \"\")\n",
    "            # 将 STREET 数据追加到 all_street_data 中\n",
    "            all_PATIENT_data += f\"{FileName}\\t\"  \n",
    "            all_PATIENT_data += f\"{phi_content}\\t\"        \n",
    "            all_PATIENT_data += f\"{start_position}\\t\"\n",
    "            all_PATIENT_data += f\"{end_position}\\t\"\n",
    "            all_PATIENT_data += f\"{PATIENT_content}\\n\"\n",
    "# 创建一个文本文件并将所有 STREET 数据写入其中\n",
    "# with open('answer_Train.txt', 'a', encoding='utf8') as file:\n",
    "with open('answer_Competion.txt', 'a', encoding='utf8') as file:    \n",
    "    file.write(all_PATIENT_data)\n",
    "print(\"所有 STREET 内容已保存到 answer.txt 文件中。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "adb349b9-5d82-4429-972a-72757f13fd6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有 STREET 内容已保存到 answer.txt 文件中。\n"
     ]
    }
   ],
   "source": [
    "data_PATIENT= selected_Stytle2_rows[['FileName','PATIENT']]\n",
    "# 初始化一个空的字符串，用于累积 STREET 数据\n",
    "all_PATIENT_data = \"\"\n",
    "# 遍历每一行并处理数据\n",
    "for index, row in data_PATIENT.iterrows():\n",
    "    FileName, PATIENT_data = row['FileName'], row['PATIENT']\n",
    "    # 如果 STREET 数据不为空\n",
    "    if not pd.isnull(PATIENT_data):\n",
    "        PATIENT_content, start_position, end_position, phi_content = PATIENT_data\n",
    "        if start_position != 'PHI: NULL':        \n",
    "            # 去除 \"PHI:\" 文字\n",
    "            phi_content = phi_content.replace(\"PHI:\", \"\")\n",
    "            # 将 STREET 数据追加到 all_street_data 中\n",
    "            all_PATIENT_data += f\"{FileName}\\t\"  \n",
    "            all_PATIENT_data += f\"{phi_content}\\t\"        \n",
    "            all_PATIENT_data += f\"{start_position}\\t\"\n",
    "            all_PATIENT_data += f\"{end_position}\\t\"\n",
    "            all_PATIENT_data += f\"{PATIENT_content}\\n\"\n",
    "# 创建一个文本文件并将所有 STREET 数据写入其中\n",
    "# with open('answer_Train.txt', 'a', encoding='utf8') as file:\n",
    "with open('answer_Competion.txt', 'a', encoding='utf8') as file:        \n",
    "    file.write(all_PATIENT_data)\n",
    "print(\"所有 STREET 内容已保存到 answer.txt 文件中。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4c1ef3-0361-4b5e-bdac-115e1daa1a70",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### 5.2 IDnum/IDMnum/資料匯出_樣式2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a1c40645-6e0b-41ee-b4d8-617eefde1aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有 STREET 内容已保存到 answer.txt 文件中。\n"
     ]
    }
   ],
   "source": [
    "data_IDnum= selected_Stytle2_rows[['FileName','IDnum']]\n",
    "# 初始化一个空的字符串，用于累积 STREET 数据\n",
    "all_IDnum_data = \"\"\n",
    "# 遍历每一行并处理数据\n",
    "for index, row in data_IDnum.iterrows():\n",
    "    FileName, IDnum_data = row['FileName'], row['IDnum']\n",
    "    # 如果 STREET 数据不为空\n",
    "    if not pd.isnull(IDnum_data):\n",
    "        IDnum_content, start_position, end_position, phi_content = IDnum_data\n",
    "        if start_position != 'PHI: NULL':        \n",
    "            # 去除 \"PHI:\" 文字\n",
    "            phi_content = phi_content.replace(\"PHI:\", \"\")\n",
    "            # 将 STREET 数据追加到 all_street_data 中\n",
    "            all_IDnum_data += f\"{FileName}\\t\"  \n",
    "            all_IDnum_data += f\"{phi_content}\\t\"        \n",
    "            all_IDnum_data += f\"{start_position}\\t\"\n",
    "            all_IDnum_data += f\"{end_position}\\t\"\n",
    "            all_IDnum_data += f\"{IDnum_content}\\n\"\n",
    "\n",
    "# 创建一个文本文件并将所有 STREET 数据写入其中\n",
    "# with open('answer_Train.txt', 'a', encoding='utf8') as file:\n",
    "with open('answer_Competion.txt', 'a', encoding='utf8') as file:        \n",
    "    file.write(all_IDnum_data)\n",
    "print(\"所有 STREET 内容已保存到 answer.txt 文件中。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "35819269-e04f-4bd1-8f77-c2ad7b866ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有 STREET 内容已保存到 answer.txt 文件中。\n"
     ]
    }
   ],
   "source": [
    "data_IDMnum= selected_Stytle2_rows[['FileName','IDMnum']]\n",
    "# 初始化一个空的字符串，用于累积 STREET 数据\n",
    "all_IDMnum_data = \"\"\n",
    "# 遍历每一行并处理数据\n",
    "for index, row in data_IDMnum.iterrows():\n",
    "    FileName, IDMnum_data = row['FileName'], row['IDMnum']\n",
    "    # 如果 STREET 数据不为空\n",
    "    if not pd.isnull(IDMnum_data):\n",
    "        IDMnum_content, start_position, end_position, phi_content = IDMnum_data\n",
    "        if start_position != 'PHI: NULL':        \n",
    "            # 去除 \"PHI:\" 文字\n",
    "            phi_content = phi_content.replace(\"PHI:\", \"\")\n",
    "            # 将 STREET 数据追加到 all_street_data 中\n",
    "            all_IDMnum_data += f\"{FileName}\\t\"  \n",
    "            all_IDMnum_data += f\"{phi_content}\\t\"        \n",
    "            all_IDMnum_data += f\"{start_position}\\t\"\n",
    "            all_IDMnum_data += f\"{end_position}\\t\"\n",
    "            all_IDMnum_data += f\"{IDMnum_content}\\n\"\n",
    "\n",
    "# 创建一个文本文件并将所有 STREET 数据写入其中\n",
    "# with open('answer_Train.txt', 'a', encoding='utf8') as file:\n",
    "with open('answer_Competion.txt', 'a', encoding='utf8') as file:        \n",
    "    file.write(all_IDMnum_data)\n",
    "print(\"所有 STREET 内容已保存到 answer.txt 文件中。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288a4f7e-06ee-4193-ae95-2691809af07c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### 5.3 SPR_no/MRN_no/資料匯出_樣式2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cca0fb79-b672-41bc-ac7f-874c50be5ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有 STREET 内容已保存到 answer.txt 文件中。\n"
     ]
    }
   ],
   "source": [
    "data_SPR_no= selected_Stytle2_rows[['FileName','SPR_no']]\n",
    "# 初始化一个空的字符串，用于累积 STREET 数据\n",
    "all_SPR_no_data = \"\"\n",
    "# 遍历每一行并处理数据\n",
    "for index, row in data_SPR_no.iterrows():\n",
    "    FileName, SPR_no_data = row['FileName'], row['SPR_no']\n",
    "    # 如果 STREET 数据不为空\n",
    "    if not pd.isnull(SPR_no_data):\n",
    "        SPR_no_content, start_position, end_position, phi_content = SPR_no_data\n",
    "        if start_position != 'PHI: NULL':        \n",
    "            # 去除 \"PHI:\" 文字\n",
    "            phi_content = phi_content.replace(\"PHI:\", \"\")\n",
    "            # 将 STREET 数据追加到 all_street_data 中\n",
    "            all_SPR_no_data += f\"{FileName}\\t\"  \n",
    "            all_SPR_no_data += f\"{phi_content}\\t\"        \n",
    "            all_SPR_no_data += f\"{start_position}\\t\"\n",
    "            all_SPR_no_data += f\"{end_position}\\t\"\n",
    "            all_SPR_no_data += f\"{SPR_no_content}\\n\"\n",
    "\n",
    "# 创建一个文本文件并将所有 STREET 数据写入其中\n",
    "# with open('answer_Train.txt', 'a', encoding='utf8') as file:\n",
    "with open('answer_Competion.txt', 'a', encoding='utf8') as file:        \n",
    "    file.write(all_SPR_no_data)\n",
    "print(\"所有 STREET 内容已保存到 answer.txt 文件中。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "30e04030-9cd8-4ab8-95e9-38e2ee4bfe7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有 STREET 内容已保存到 answer.txt 文件中。\n"
     ]
    }
   ],
   "source": [
    "data_MRN_no= selected_Stytle2_rows[['FileName','MRN_no']]\n",
    "# 初始化一个空的字符串，用于累积 STREET 数据\n",
    "all_MRN_no_data = \"\"\n",
    "# 遍历每一行并处理数据\n",
    "for index, row in data_MRN_no.iterrows():\n",
    "    FileName, MRN_no_data = row['FileName'], row['MRN_no']\n",
    "    # 如果 STREET 数据不为空\n",
    "    if not pd.isnull(MRN_no_data):\n",
    "        MRN_no_content, start_position, end_position, phi_content = MRN_no_data\n",
    "        if start_position != 'PHI: NULL':        \n",
    "            # 去除 \"PHI:\" 文字\n",
    "            phi_content = phi_content.replace(\"PHI:\", \"\")\n",
    "            # 将 STREET 数据追加到 all_street_data 中\n",
    "            all_MRN_no_data += f\"{FileName}\\t\"  \n",
    "            all_MRN_no_data += f\"{phi_content}\\t\"        \n",
    "            all_MRN_no_data += f\"{start_position}\\t\"\n",
    "            all_MRN_no_data += f\"{end_position}\\t\"\n",
    "            all_MRN_no_data += f\"{MRN_no_content}\\n\"\n",
    "\n",
    "# 创建一个文本文件并将所有 STREET 数据写入其中\n",
    "# with open('answer_Train.txt', 'a', encoding='utf8') as file:\n",
    "with open('answer_Competion.txt', 'a', encoding='utf8') as file:        \n",
    "    file.write(all_MRN_no_data)\n",
    "print(\"所有 STREET 内容已保存到 answer.txt 文件中。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff7e2b3-3ddd-42b9-a477-d539d7dac6d3",
   "metadata": {},
   "source": [
    "##### 5.4 DR資料匯出_樣式2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a0b8a862-579f-461d-94f1-9e4a608c422f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有 STREET 内容已保存到 answer.txt 文件中。\n"
     ]
    }
   ],
   "source": [
    "data_DR= selected_Stytle2_rows[['FileName','DR']]\n",
    "# 初始化一个空的字符串，用于累积 STREET 数据\n",
    "all_DR_data = \"\"\n",
    "# 遍历每一行并处理数据\n",
    "for index, row in data_DR.iterrows():\n",
    "    FileName, DR_data = row['FileName'], row['DR']\n",
    "    # 如果 STREET 数据不为空\n",
    "    if not pd.isnull(DR_data):\n",
    "        DR_content, start_position, end_position, phi_content = DR_data\n",
    "        if start_position != 'PHI: NULL':        \n",
    "            # 去除 \"PHI:\" 文字\n",
    "            phi_content = phi_content.replace(\"PHI:\", \"\")\n",
    "            # 将 STREET 数据追加到 all_street_data 中\n",
    "            all_DR_data += f\"{FileName}\\t\"  \n",
    "            all_DR_data += f\"{phi_content}\\t\"        \n",
    "            all_DR_data += f\"{start_position}\\t\"\n",
    "            all_DR_data += f\"{end_position}\\t\"\n",
    "            all_DR_data += f\"{DR_content}\\n\"\n",
    "\n",
    "# 创建一个文本文件并将所有 STREET 数据写入其中\n",
    "# with open('answer_Train.txt', 'a', encoding='utf8') as file:\n",
    "with open('answer_Competion.txt', 'a', encoding='utf8') as file:        \n",
    "    file.write(all_DR_data)\n",
    "print(\"所有 STREET 内容已保存到 answer.txt 文件中。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4836c7ba-49a4-48ca-a624-675b02939cef",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### 5.5 DOB資料匯出(同時完成轉換)_樣式2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6feadf44-5711-4ee5-865c-5b0d9c1f4981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有 STREET 内容已保存到 answer.txt 文件中。\n"
     ]
    }
   ],
   "source": [
    "data_DOB= selected_Stytle2_rows[['FileName','D.O.B']]\n",
    "# 初始化一个空的字符串，用于累积 STREET 数据\n",
    "all_DOB_data = \"\"\n",
    "# 遍历每一行并处理数据\n",
    "for index, row in data_DOB.iterrows():\n",
    "    FileName, DOB_data = row['FileName'], row['D.O.B']\n",
    "    # 如果 STREET 数据不为空\n",
    "    if not pd.isnull(DOB_data):\n",
    "        DOB_content, start_position, end_position, phi_content = DOB_data\n",
    "        if start_position != 'PHI: NULL':\n",
    "            DOB_content_Time=DOB_Tdatetime(DOB_content)\n",
    "            # 去除 \"PHI:\" 文字\n",
    "            phi_content = phi_content.replace(\"PHI:\", \"\")\n",
    "            # 将 STREET 数据追加到 all_street_data 中\n",
    "            all_DOB_data += f\"{FileName}\\t\"  \n",
    "            all_DOB_data += f\"{phi_content}\\t\"        \n",
    "            all_DOB_data += f\"{start_position}\\t\"\n",
    "            all_DOB_data += f\"{end_position}\\t\"\n",
    "            all_DOB_data += f\"{DOB_content}\\t\"\n",
    "            all_DOB_data += f\"{DOB_content_Time}\\n\"\n",
    "\n",
    "# 创建一个文本文件并将所有 STREET 数据写入其中\n",
    "# with open('answer_Train.txt', 'a', encoding='utf8') as file:\n",
    "with open('answer_Competion.txt', 'a', encoding='utf8') as file:        \n",
    "    file.write(all_DOB_data)\n",
    "print(\"所有 STREET 内容已保存到 answer.txt 文件中。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99948393-bb7f-4b3e-bf19-39831c3ef301",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### 5.6 Collected資料匯出(同時完成轉換)_樣式2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "47a61bb3-6e92-4cab-8b2e-dee5359993a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有 STREET 内容已保存到 answer.txt 文件中。\n"
     ]
    }
   ],
   "source": [
    "data_Collected= selected_Stytle2_rows[['FileName','Collected']]\n",
    "# 初始化一个空的字符串，用于累积 STREET 数据\n",
    "all_Collected_data = \"\"\n",
    "# 遍历每一行并处理数据\n",
    "for index, row in data_Collected.iterrows():\n",
    "    FileName, Collected_data = row['FileName'], row['Collected']\n",
    "    # 如果 STREET 数据不为空\n",
    "    if not pd.isnull(Collected_data):\n",
    "        Collected_content, start_position, end_position, phi_content = Collected_data\n",
    "        if start_position != 'PHI: NULL' and Collected_content !='Unknown at :':        \n",
    "            Collected_content_Time=Collected_Tdatetime(Collected_content)\n",
    "            if Collected_content_Time != 'PHI:NULL':\n",
    "                # 去除 \"PHI:\" 文字\n",
    "                phi_content = phi_content.replace(\"PHI:\", \"\")\n",
    "                # 将 STREET 数据追加到 all_street_data 中\n",
    "                all_Collected_data += f\"{FileName}\\t\"  \n",
    "                all_Collected_data += f\"{phi_content}\\t\"        \n",
    "                all_Collected_data += f\"{start_position}\\t\"\n",
    "                all_Collected_data += f\"{end_position}\\t\"\n",
    "                all_Collected_data += f\"{Collected_content}\\t\"\n",
    "                all_Collected_data += f\"{Collected_content_Time}\\n\"\n",
    "# 创建一个文本文件并将所有 STREET 数据写入其中\n",
    "# with open('answer_Train.txt', 'a', encoding='utf8') as file:\n",
    "with open('answer_Competion.txt', 'a', encoding='utf8') as file:        \n",
    "    file.write(all_Collected_data)\n",
    "print(\"所有 STREET 内容已保存到 answer.txt 文件中。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11b3a79-bd2f-4a16-82bb-a846ac9b9bac",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### 5.7 Location資料匯出_樣式2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "adf84fad-c09a-493c-91e4-5a9aa5882db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有 STREET 内容已保存到 answer.txt 文件中。\n"
     ]
    }
   ],
   "source": [
    "data_Location= selected_Stytle2_rows[['FileName','Location']]\n",
    "# 初始化一个空的字符串，用于累积 STREET 数据\n",
    "all_Location_data = \"\"\n",
    "# 遍历每一行并处理数据\n",
    "for index, row in data_Location.iterrows():\n",
    "    FileName, Location_data = row['FileName'], row['Location']\n",
    "    # 如果 STREET 数据不为空\n",
    "    if not pd.isnull(Location_data):\n",
    "        Location_content, start_position, end_position, phi_content = Location_data\n",
    "        if start_position != 'PHI: NULL':        \n",
    "            # 去除 \"PHI:\" 文字\n",
    "            phi_content = phi_content.replace(\"PHI:\", \"\")\n",
    "            # 将 STREET 数据追加到 all_street_data 中\n",
    "            all_Location_data += f\"{FileName}\\t\"  \n",
    "            all_Location_data += f\"{phi_content}\\t\"        \n",
    "            all_Location_data += f\"{start_position}\\t\"\n",
    "            all_Location_data += f\"{end_position}\\t\"\n",
    "            all_Location_data += f\"{Location_content}\\n\"\n",
    "\n",
    "# 创建一个文本文件并将所有 STREET 数据写入其中\n",
    "# with open('answer_Train.txt', 'a', encoding='utf8') as file:\n",
    "with open('answer_Competion.txt', 'a', encoding='utf8') as file:        \n",
    "    file.write(all_Location_data)\n",
    "print(\"所有 STREET 内容已保存到 answer.txt 文件中。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2240441b-fd83-4ebc-b9de-8f83673fc0f9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### 5.8 Site_name資料匯出_樣式2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2f7293a1-dcf6-4119-a8d4-f79332a741a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有 STREET 内容已保存到 answer.txt 文件中。\n"
     ]
    }
   ],
   "source": [
    "data_Sitename= selected_Stytle2_rows[['FileName','Site_name']]\n",
    "# 初始化一个空的字符串，用于累积 STREET 数据\n",
    "all_Sitename_data = \"\"\n",
    "# 遍历每一行并处理数据\n",
    "for index, row in data_Sitename.iterrows():\n",
    "    FileName, Sitename_data = row['FileName'], row['Site_name']\n",
    "    # 如果 STREET 数据不为空\n",
    "    if not pd.isnull(Sitename_data):\n",
    "        Sitename_content, start_position, end_position, phi_content = Sitename_data\n",
    "        if start_position != 'PHI: NULL':        \n",
    "            # 去除 \"PHI:\" 文字\n",
    "            phi_content = phi_content.replace(\"PHI:\", \"\")\n",
    "            # 将 STREET 数据追加到 all_street_data 中\n",
    "            all_Sitename_data += f\"{FileName}\\t\"  \n",
    "            all_Sitename_data += f\"{phi_content}\\t\"        \n",
    "            all_Sitename_data += f\"{start_position}\\t\"\n",
    "            all_Sitename_data += f\"{end_position}\\t\"\n",
    "            all_Sitename_data += f\"{Sitename_content}\\n\"\n",
    "\n",
    "# 创建一个文本文件并将所有 STREET 数据写入其中\n",
    "# with open('answer_Train.txt', 'a', encoding='utf8') as file:\n",
    "with open('answer_Competion.txt', 'a', encoding='utf8') as file:        \n",
    "    file.write(all_Sitename_data)\n",
    "print(\"所有 STREET 内容已保存到 answer.txt 文件中。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950b8136-c163-482b-859b-32d031094f14",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### 5.9 Sex資料匯出_樣式2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "96001452-78ea-48f1-9f63-116d6ecf9343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_Sex= selected_Stytle2_rows[['FileName','Sex']]\n",
    "# # 初始化一个空的字符串，用于累积 STREET 数据\n",
    "# all_Sex_data = \"\"\n",
    "# # 遍历每一行并处理数据\n",
    "# for index, row in data_Sex.iterrows():\n",
    "#     FileName, Sex_data = row['FileName'], row['Sex']\n",
    "#     # 如果 STREET 数据不为空\n",
    "#     if not pd.isnull(Sex_data):\n",
    "#         Sex_content, start_position, end_position, phi_content = Sex_data\n",
    "#         if start_position != 'PHI: NULL':        \n",
    "#             # 去除 \"PHI:\" 文字\n",
    "#             phi_content = phi_content.replace(\"PHI:\", \"\")\n",
    "#             # 将 STREET 数据追加到 all_street_data 中\n",
    "#             all_Sex_data += f\"{FileName}\\t\"  \n",
    "#             all_Sex_data += f\"{phi_content}\\t\"        \n",
    "#             all_Sex_data += f\"{start_position}\\t\"\n",
    "#             all_Sex_data += f\"{end_position}\\t\"\n",
    "#             all_Sex_data += f\"{Sex_content}\\n\"\n",
    "\n",
    "# # 创建一个文本文件并将所有 STREET 数据写入其中\n",
    "# # with open('answer_Train.txt', 'a', encoding='utf8') as file:\n",
    "# with open('answer_Competion.txt', 'a', encoding='utf8') as file:        \n",
    "#     file.write(all_Sex_data)\n",
    "# print(\"所有 STREET 内容已保存到 answer.txt 文件中。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efd64ff-9982-49e6-8479-e0058808aea2",
   "metadata": {},
   "source": [
    "#### 樣式3查詢結果匯出"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9906545-1d1a-4344-a588-8082c64d09fc",
   "metadata": {},
   "source": [
    "##### 5.1 PATIENT資料匯出_樣式3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "43af3b6d-85a3-4acb-bd75-1fe8dc247f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有 STREET 内容已保存到 answer.txt 文件中。\n"
     ]
    }
   ],
   "source": [
    "data_PATIENT= selected_Stytle3_rows[['FileName','PATIENT']]\n",
    "# 初始化一个空的字符串，用于累积 STREET 数据\n",
    "all_PATIENT_data = \"\"\n",
    "# 遍历每一行并处理数据\n",
    "for index, row in data_PATIENT.iterrows():\n",
    "    FileName, PATIENT_data = row['FileName'], row['PATIENT']\n",
    "    # 如果 STREET 数据不为空\n",
    "    if not pd.isnull(PATIENT_data):\n",
    "        PATIENT_content, start_position, end_position, phi_content = PATIENT_data\n",
    "        if start_position != 'PHI: NULL':        \n",
    "            # 去除 \"PHI:\" 文字\n",
    "            phi_content = phi_content.replace(\"PHI:\", \"\")\n",
    "            # 将 STREET 数据追加到 all_street_data 中\n",
    "            all_PATIENT_data += f\"{FileName}\\t\"  \n",
    "            all_PATIENT_data += f\"{phi_content}\\t\"        \n",
    "            all_PATIENT_data += f\"{start_position}\\t\"\n",
    "            all_PATIENT_data += f\"{end_position}\\t\"\n",
    "            all_PATIENT_data += f\"{PATIENT_content}\\n\"\n",
    "\n",
    "# 创建一个文本文件并将所有 STREET 数据写入其中\n",
    "# with open('answer_Train.txt', 'a', encoding='utf8') as file:\n",
    "with open('answer_Competion.txt', 'a', encoding='utf8') as file:        \n",
    "    file.write(all_PATIENT_data)\n",
    "print(\"所有 STREET 内容已保存到 answer.txt 文件中。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ed170e5f-182a-4edb-9507-98ce0d083900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有 STREET 内容已保存到 answer.txt 文件中。\n"
     ]
    }
   ],
   "source": [
    "data_FirstName= selected_Stytle3_rows[['FileName','FirstName']]\n",
    "# 初始化一个空的字符串，用于累积 STREET 数据\n",
    "all_FirstName_data = \"\"\n",
    "# 遍历每一行并处理数据\n",
    "for index, row in data_FirstName.iterrows():\n",
    "    FileName, FirstName_data = row['FileName'], row['FirstName']\n",
    "    # 如果 STREET 数据不为空\n",
    "    if not pd.isnull(FirstName_data):\n",
    "        FirstName_content, start_position, end_position, phi_content = FirstName_data\n",
    "        if start_position != 'PHI: NULL':        \n",
    "            # 去除 \"PHI:\" 文字\n",
    "            phi_content = phi_content.replace(\"PHI:\", \"\")\n",
    "            # 将 STREET 数据追加到 all_street_data 中\n",
    "            all_FirstName_data += f\"{FileName}\\t\"  \n",
    "            all_FirstName_data += f\"{phi_content}\\t\"        \n",
    "            all_FirstName_data += f\"{start_position}\\t\"\n",
    "            all_FirstName_data += f\"{end_position}\\t\"\n",
    "            all_FirstName_data += f\"{FirstName_content}\\n\"\n",
    "\n",
    "# 创建一个文本文件并将所有 STREET 数据写入其中\n",
    "# with open('answer_Train.txt', 'a', encoding='utf8') as file:\n",
    "with open('answer_Competion.txt', 'a', encoding='utf8') as file:        \n",
    "    file.write(all_FirstName_data)\n",
    "print(\"所有 STREET 内容已保存到 answer.txt 文件中。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "892be606-ca24-474c-bd82-ad19bf86a982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有 STREET 内容已保存到 answer.txt 文件中。\n"
     ]
    }
   ],
   "source": [
    "data_MiddleName= selected_Stytle3_rows[['FileName','MiddleName']]\n",
    "# 初始化一个空的字符串，用于累积 STREET 数据\n",
    "all_MiddleName_data = \"\"\n",
    "# 遍历每一行并处理数据\n",
    "for index, row in data_MiddleName.iterrows():\n",
    "    FileName, MiddleName_data = row['FileName'], row['MiddleName']\n",
    "    # 如果 STREET 数据不为空\n",
    "    if not pd.isnull(MiddleName_data):\n",
    "        MiddleName_content, start_position, end_position, phi_content = MiddleName_data\n",
    "        if start_position != 'PHI: NULL':        \n",
    "            # 去除 \"PHI:\" 文字\n",
    "            phi_content = phi_content.replace(\"PHI:\", \"\")\n",
    "            # 将 STREET 数据追加到 all_street_data 中\n",
    "            all_MiddleName_data += f\"{FileName}\\t\"  \n",
    "            all_MiddleName_data += f\"{phi_content}\\t\"        \n",
    "            all_MiddleName_data += f\"{start_position}\\t\"\n",
    "            all_MiddleName_data += f\"{end_position}\\t\"\n",
    "            all_MiddleName_data += f\"{MiddleName_content}\\n\"\n",
    "\n",
    "# 创建一个文本文件并将所有 STREET 数据写入其中\n",
    "# with open('answer_Train.txt', 'a', encoding='utf8') as file:\n",
    "with open('answer_Competion.txt', 'a', encoding='utf8') as file:        \n",
    "    file.write(all_MiddleName_data)\n",
    "print(\"所有 STREET 内容已保存到 answer.txt 文件中。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "203652fb-bf4c-45b4-9649-29d6f703b9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有 STREET 内容已保存到 answer.txt 文件中。\n"
     ]
    }
   ],
   "source": [
    "data_LastName= selected_Stytle3_rows[['FileName','LastName']]\n",
    "# 初始化一个空的字符串，用于累积 STREET 数据\n",
    "all_LastName_data = \"\"\n",
    "# 遍历每一行并处理数据\n",
    "for index, row in data_LastName.iterrows():\n",
    "    FileName, LastName_data = row['FileName'], row['LastName']\n",
    "    # 如果 STREET 数据不为空\n",
    "    if not pd.isnull(LastName_data):\n",
    "        LastName_content, start_position, end_position, phi_content = LastName_data\n",
    "        if start_position != 'PHI: NULL':        \n",
    "            # 去除 \"PHI:\" 文字\n",
    "            phi_content = phi_content.replace(\"PHI:\", \"\")\n",
    "            # 将 STREET 数据追加到 all_street_data 中\n",
    "            all_LastName_data += f\"{FileName}\\t\"  \n",
    "            all_LastName_data += f\"{phi_content}\\t\"        \n",
    "            all_LastName_data += f\"{start_position}\\t\"\n",
    "            all_LastName_data += f\"{end_position}\\t\"\n",
    "            all_LastName_data += f\"{LastName_content}\\n\"\n",
    "\n",
    "# 创建一个文本文件并将所有 STREET 数据写入其中\n",
    "# with open('answer_Train.txt', 'a', encoding='utf8') as file:\n",
    "with open('answer_Competion.txt', 'a', encoding='utf8') as file:        \n",
    "    file.write(all_LastName_data)\n",
    "print(\"所有 STREET 内容已保存到 answer.txt 文件中。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4650e2c2-7c7c-4111-a0ed-702487d9387d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### 5.2 DR資料匯出_樣式3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f32d17b7-399d-4b24-9af8-558f835794a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有 STREET 内容已保存到 answer.txt 文件中。\n"
     ]
    }
   ],
   "source": [
    "data_Doctorname= selected_Stytle3_rows[['FileName','Doctorname']]\n",
    "# 初始化一个空的字符串，用于累积 STREET 数据\n",
    "all_Doctorname_data = \"\"\n",
    "# 遍历每一行并处理数据\n",
    "for index, row in data_Doctorname.iterrows():\n",
    "    FileName, Doctorname_data = row['FileName'], row['Doctorname']\n",
    "    # 如果 STREET 数据不为空\n",
    "    if not pd.isnull(Doctorname_data):\n",
    "        Doctorname_content, start_position, end_position, phi_content = Doctorname_data\n",
    "        if start_position != 'PHI: NULL':        \n",
    "            # 去除 \"PHI:\" 文字\n",
    "            phi_content = phi_content.replace(\"PHI:\", \"\")\n",
    "            # 将 STREET 数据追加到 all_street_data 中\n",
    "            all_Doctorname_data += f\"{FileName}\\t\"  \n",
    "            all_Doctorname_data += f\"{phi_content}\\t\"        \n",
    "            all_Doctorname_data += f\"{start_position}\\t\"\n",
    "            all_Doctorname_data += f\"{end_position}\\t\"\n",
    "            all_Doctorname_data += f\"{Doctorname_content}\\n\"\n",
    "\n",
    "# 创建一个文本文件并将所有 STREET 数据写入其中\n",
    "# with open('answer_Train.txt', 'a', encoding='utf8') as file:\n",
    "with open('answer_Competion.txt', 'a', encoding='utf8') as file:        \n",
    "    file.write(all_Doctorname_data)\n",
    "print(\"所有 STREET 内容已保存到 answer.txt 文件中。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ecdcae-56f8-4a5f-abb6-3c5634fafd23",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### 5.3 SpecimenReceivedDate資料匯出_樣式3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2427d47b-11e1-42d4-8e91-e0b5550e3fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有 STREET 内容已保存到 answer.txt 文件中。\n"
     ]
    }
   ],
   "source": [
    "data_SRD= selected_Stytle3_rows[['FileName','SpecimenReceivedDate']]\n",
    "# 初始化一个空的字符串，用于累积 STREET 数据\n",
    "all_SRD_data = \"\"\n",
    "# 遍历每一行并处理数据\n",
    "for index, row in data_SRD.iterrows():\n",
    "    FileName, SRD_ = row['FileName'], row['SpecimenReceivedDate']\n",
    "    # 如果 STREET 数据不为空\n",
    "    if not pd.isnull(SRD_):\n",
    "        SRD_content, start_position, end_position, phi_content = SRD_\n",
    "        if start_position != 'PHI: NULL':\n",
    "            SRD_content_Time=Tdatetime(SRD_content)            \n",
    "            # 去除 \"PHI:\" 文字\n",
    "            phi_content = phi_content.replace(\"PHI:\", \"\")\n",
    "            # 将 STREET 数据追加到 all_street_data 中\n",
    "            all_SRD_data += f\"{FileName}\\t\"  \n",
    "            all_SRD_data += f\"{phi_content}\\t\"        \n",
    "            all_SRD_data += f\"{start_position}\\t\"\n",
    "            all_SRD_data += f\"{end_position}\\t\"\n",
    "            all_SRD_data += f\"{SRD_content_Time}\\n\"\n",
    "\n",
    "# 创建一个文本文件并将所有 STREET 数据写入其中\n",
    "# with open('answer_Train.txt', 'a', encoding='utf8') as file:\n",
    "with open('answer_Competion.txt', 'a', encoding='utf8') as file:        \n",
    "    file.write(all_SRD_data)\n",
    "print(\"所有 STREET 内容已保存到 answer.txt 文件中。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66668633-f299-453e-8fbd-9296425847aa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### 5.4 Collected資料匯出_樣式3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "142638ea-c1ff-4058-a81a-b5dfdc20d5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有 STREET 内容已保存到 answer.txt 文件中。\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "data_Collected= selected_Stytle3_rows[['FileName','Collected']]\n",
    "# 初始化一个空的字符串，用于累积 STREET 数据\n",
    "all_Collected_data = \"\"\n",
    "# 遍历每一行并处理数据\n",
    "for index, row in data_Collected.iterrows():\n",
    "    FileName, Collected_data = row['FileName'], row['Collected']\n",
    "    # 如果 STREET 数据不为空\n",
    "    if not pd.isnull(Collected_data):\n",
    "        Collected_content, start_position, end_position, phi_content = Collected_data\n",
    "        if start_position != 'PHI: NULL' and Collected_content !='Unknown at :':        \n",
    "            Collected_content_Time=Collected_Tdatetime(Collected_content)\n",
    "            if Collected_content_Time != 'PHI:NULL':\n",
    "                # 去除 \"PHI:\" 文字\n",
    "                phi_content = phi_content.replace(\"PHI:\", \"\")\n",
    "                # 将 STREET 数据追加到 all_street_data 中\n",
    "                all_Collected_data += f\"{FileName}\\t\"  \n",
    "                all_Collected_data += f\"{phi_content}\\t\"        \n",
    "                all_Collected_data += f\"{start_position}\\t\"\n",
    "                all_Collected_data += f\"{end_position}\\t\"\n",
    "                all_Collected_data += f\"{Collected_content}\\t\"\n",
    "                all_Collected_data += f\"{Collected_content_Time}\\n\"\n",
    "# 创建一个文本文件并将所有 STREET 数据写入其中\n",
    "# with open('answer_Train.txt', 'a', encoding='utf8') as file:\n",
    "with open('answer_Competion.txt', 'a', encoding='utf8') as file:        \n",
    "    file.write(all_Collected_data)\n",
    "print(\"所有 STREET 内容已保存到 answer.txt 文件中。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81809ac-5275-4b4f-b214-240f7e51eb24",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### 5.5 SPRID/MRN/資料匯出_樣式3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0dc083ed-3f64-4857-a281-70e94c46f2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有 STREET 内容已保存到 answer.txt 文件中。\n"
     ]
    }
   ],
   "source": [
    "data_SPRID= selected_Stytle3_rows[['FileName','SPRID']]\n",
    "# 初始化一个空的字符串，用于累积 STREET 数据\n",
    "all_SPRID_data = \"\"\n",
    "# 遍历每一行并处理数据\n",
    "for index, row in data_SPRID.iterrows():\n",
    "    FileName, SPRID_data = row['FileName'], row['SPRID']\n",
    "    # 如果 STREET 数据不为空\n",
    "    if not pd.isnull(SPRID_data):\n",
    "        SPRID_content, start_position, end_position, phi_content = SPRID_data\n",
    "        if start_position != 'PHI: NULL':        \n",
    "            # 去除 \"PHI:\" 文字\n",
    "            phi_content = phi_content.replace(\"PHI:\", \"\")\n",
    "            # 将 STREET 数据追加到 all_street_data 中\n",
    "            all_SPRID_data += f\"{FileName}\\t\"  \n",
    "            all_SPRID_data += f\"{phi_content}\\t\"        \n",
    "            all_SPRID_data += f\"{start_position}\\t\"\n",
    "            all_SPRID_data += f\"{end_position}\\t\"\n",
    "            all_SPRID_data += f\"{SPRID_content}\\n\"\n",
    "\n",
    "# 创建一个文本文件并将所有 STREET 数据写入其中\n",
    "# with open('answer_Train.txt', 'a', encoding='utf8') as file:\n",
    "with open('answer_Competion.txt', 'a', encoding='utf8') as file:        \n",
    "    file.write(all_SPRID_data)\n",
    "print(\"所有 STREET 内容已保存到 answer.txt 文件中。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1957ff54-af28-42ca-8bc4-f6325ecc55e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有 STREET 内容已保存到 answer.txt 文件中。\n"
     ]
    }
   ],
   "source": [
    "data_MRN= selected_Stytle3_rows[['FileName','MRN']]\n",
    "# 初始化一个空的字符串，用于累积 STREET 数据\n",
    "all_MRN_data = \"\"\n",
    "# 遍历每一行并处理数据\n",
    "for index, row in data_MRN.iterrows():\n",
    "    FileName, MRN_data = row['FileName'], row['MRN']\n",
    "    # 如果 STREET 数据不为空\n",
    "    if not pd.isnull(MRN_data):\n",
    "        MRN_content, start_position, end_position, phi_content = MRN_data\n",
    "        if start_position != 'PHI: NULL':        \n",
    "            # 去除 \"PHI:\" 文字\n",
    "            phi_content = phi_content.replace(\"PHI:\", \"\")\n",
    "            # 将 STREET 数据追加到 all_street_data 中\n",
    "            all_MRN_data += f\"{FileName}\\t\"  \n",
    "            all_MRN_data += f\"{phi_content}\\t\"        \n",
    "            all_MRN_data += f\"{start_position}\\t\"\n",
    "            all_MRN_data += f\"{end_position}\\t\"\n",
    "            all_MRN_data += f\"{MRN_content}\\n\"\n",
    "\n",
    "# 创建一个文本文件并将所有 STREET 数据写入其中\n",
    "# with open('answer_Train.txt', 'a', encoding='utf8') as file:\n",
    "with open('answer_Competion.txt', 'a', encoding='utf8') as file:        \n",
    "    file.write(all_MRN_data)\n",
    "print(\"所有 STREET 内容已保存到 answer.txt 文件中。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63422d4-b16d-4368-a960-e302de809003",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### 5.6 Location資料匯出_樣式3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dc49d737-8670-421e-a3e3-feaf137062e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有 STREET 内容已保存到 answer.txt 文件中。\n"
     ]
    }
   ],
   "source": [
    "data_Location= selected_Stytle3_rows[['FileName','Location']]\n",
    "# 初始化一个空的字符串，用于累积 STREET 数据\n",
    "all_Location_data = \"\"\n",
    "# 遍历每一行并处理数据\n",
    "for index, row in data_Location.iterrows():\n",
    "    FileName, Location_data = row['FileName'], row['Location']\n",
    "    # 如果 STREET 数据不为空\n",
    "    if not pd.isnull(Location_data):\n",
    "        Location_content, start_position, end_position, phi_content = Location_data\n",
    "        if start_position != 'PHI: NULL':        \n",
    "            # 去除 \"PHI:\" 文字\n",
    "            phi_content = phi_content.replace(\"PHI:\", \"\")\n",
    "            # 将 STREET 数据追加到 all_street_data 中\n",
    "            all_Location_data += f\"{FileName}\\t\"  \n",
    "            all_Location_data += f\"{phi_content}\\t\"        \n",
    "            all_Location_data += f\"{start_position}\\t\"\n",
    "            all_Location_data += f\"{end_position}\\t\"\n",
    "            all_Location_data += f\"{Location_content}\\n\"\n",
    "\n",
    "# 创建一个文本文件并将所有 STREET 数据写入其中\n",
    "# with open('answer_Train.txt', 'a', encoding='utf8') as file:\n",
    "with open('answer_Competion.txt', 'a', encoding='utf8') as file:        \n",
    "    file.write(all_Location_data)\n",
    "print(\"所有 STREET 内容已保存到 answer.txt 文件中。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc83348-f876-43a8-9f7c-03c94d05ccab",
   "metadata": {},
   "source": [
    "##### 5.7 Site_name資料匯出_樣式3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5f1bdda2-5a0f-4409-9ec1-91054a349533",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有 STREET 内容已保存到 answer.txt 文件中。\n"
     ]
    }
   ],
   "source": [
    "data_SiteName= selected_Stytle3_rows[['FileName','SiteName']]\n",
    "# 初始化一个空的字符串，用于累积 STREET 数据\n",
    "all_SiteName_data = \"\"\n",
    "# 遍历每一行并处理数据\n",
    "for index, row in data_SiteName.iterrows():\n",
    "    FileName, SiteName_data = row['FileName'], row['SiteName']\n",
    "    # 如果 STREET 数据不为空\n",
    "    if not pd.isnull(SiteName_data):\n",
    "        SiteName_content, start_position, end_position, phi_content = SiteName_data\n",
    "        if start_position != 'PHI: NULL':        \n",
    "            # 去除 \"PHI:\" 文字\n",
    "            phi_content = phi_content.replace(\"PHI:\", \"\")\n",
    "            # 将 STREET 数据追加到 all_street_data 中\n",
    "            all_SiteName_data += f\"{FileName}\\t\"  \n",
    "            all_SiteName_data += f\"{phi_content}\\t\"        \n",
    "            all_SiteName_data += f\"{start_position}\\t\"\n",
    "            all_SiteName_data += f\"{end_position}\\t\"\n",
    "            all_SiteName_data += f\"{SiteName_content}\\n\"\n",
    "\n",
    "# 创建一个文本文件并将所有 STREET 数据写入其中\n",
    "# with open('answer_Train.txt', 'a', encoding='utf8') as file:\n",
    "with open('answer_Competion.txt', 'a', encoding='utf8') as file:        \n",
    "    file.write(all_SiteName_data)\n",
    "print(\"所有 STREET 内容已保存到 answer.txt 文件中。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68e7bc1-b7d4-4df6-821f-01848d26bbc6",
   "metadata": {},
   "source": [
    "##### 5.8 Gender資料匯出_樣式3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1c27ff0e-d4b9-4c03-9287-42cf68c732ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_Gender= selected_Stytle3_rows[['FileName','Gender']]\n",
    "# # 初始化一个空的字符串，用于累积 STREET 数据\n",
    "# all_Gender_data = \"\"\n",
    "# # 遍历每一行并处理数据\n",
    "# for index, row in data_Gender.iterrows():\n",
    "#     FileName, Gender_data = row['FileName'], row['Gender']\n",
    "#     # 如果 STREET 数据不为空\n",
    "#     if not pd.isnull(Gender_data):\n",
    "#         Gender_content, start_position, end_position, phi_content = Gender_data\n",
    "#         if start_position != 'PHI: NULL':        \n",
    "#             # 去除 \"PHI:\" 文字\n",
    "#             phi_content = phi_content.replace(\"PHI:\", \"\")\n",
    "#             # 将 STREET 数据追加到 all_street_data 中\n",
    "#             all_Gender_data += f\"{FileName}\\t\"  \n",
    "#             all_Gender_data += f\"{phi_content}\\t\"        \n",
    "#             all_Gender_data += f\"{start_position}\\t\"\n",
    "#             all_Gender_data += f\"{end_position}\\t\"\n",
    "#             all_Gender_data += f\"{Gender_content}\\n\"\n",
    "\n",
    "# # 创建一个文本文件并将所有 STREET 数据写入其中\n",
    "# # with open('answer_Train.txt', 'a', encoding='utf8') as file:\n",
    "# with open('answer_valid.txt', 'a', encoding='utf8') as file:        \n",
    "#     file.write(all_Gender_data)\n",
    "# print(\"所有 STREET 内容已保存到 answer.txt 文件中。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce0b43b-c066-48c0-8318-6dce9453ea09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
